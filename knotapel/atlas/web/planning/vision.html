<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>planning/vision.md</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Nunito:wght@400;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <nav><a href="../index.html">← Back to Index</a></nav><hr>
    <h1>DKC Vision &amp; Long-Term Directions</h1>
<p>Where the research is going, beyond the next few demos. Updated during defrag or when significant vision discussions happen in conversation.</p>
<p>---</p>
<h2>The Hybrid LLM Thesis</h2>
<p><strong>Core idea:</strong> A language model where some knowledge is <em>compiled</em> (from taxonomy and syllogisms, provably correct, dynamically updatable) and some is <em>trained</em> (from corpus, statistically approximate, fixed after training).</p>
<p><strong>The pipeline:</strong> <code></code>` Taxonomy / Syllogism Graph  →  Knots / Braids  →  DKC  →  Exact Compiled Weights                                                               ↓ Small Corpus  →  Statistical Training  →  Trained Weights  →  Hybrid Model <code></code>`</p>
<p><strong>Why this matters:</strong> <ul> <li>Current LLMs encode ALL knowledge statistically. Facts can hallucinate.</li> <li>Context stuffing (RAG) is a bandaid — limited, expensive per-inference.</li> <li>Fine-tuning is expensive, slow, and catastrophically forgets.</li> <li>Compiled weights would be provably correct, dynamically updatable, and don't consume context window.</li> </ul>
<p><strong>The DKC strengths that enable this:</strong> <ul> <li>No training needed → fast recompilation (add fact → recompile → done)</li> <li>Exactness → facts that can't hallucinate</li> <li>Finite catalog → bounded cost per fact</li> <li>Interpretability → removable facts (trace which weights encode which relations)</li> </ul>
<p><strong>Execution model:</strong> <code></code>` words → tokens → net → tokens → words <code></code>` This is the fundamental loop. Words are both the input format and output format. The net is the compiled+trained hybrid. One limitation of current LLMs: the finite token set means you cannot use words outside the vocabulary as input or output.</p>
<p><strong>The value proposition:</strong> An LLM where you can add, remove, and correct factual knowledge in real-time without retraining, without context stuffing, and with provable correctness for the hard-fact portion.</p>
<p><strong>Philosophical grounding:</strong> Maps onto the scholastic distinction between <em>scientia</em> (demonstrative knowledge from first principles — compiled) and <em>opinio</em> (probable knowledge from observation — trained). The taxonomy IS the first principles; the corpus IS the observations.</p>
<p>---</p>
<h2>Opaque Tokens</h2>
<p><strong>Core insight:</strong> Because we compile our net and have granular transparency of its execution, we can introduce a fundamentally new kind of token — "opaque tokens" (also: passthrough tokens, argument tokens).</p>
<p>A syllogism (or any logical function) does not need to know the <em>value</em> of its arguments — only their logical nature (term, predicate, subject, etc.). "All X are Y, all Y are Z, therefore all X are Z" works regardless of what X, Y, Z are.</p>
<p><strong>Mechanism:</strong> Opaque tokens flow through the compiled portion of the net. The net operates on logical structure, not content. Execution tracks which input positions flow to which output positions. At output, opaque tokens are replaced with the original input values.</p>
<p>This is essentially <strong>type-level computation</strong> — the net reasons about relationships between slots, not about what fills the slots.</p>
<p><strong>Implications:</strong> <ul> <li>Breaks the finite-vocabulary limitation. New proper nouns, technical terms, any string can be an opaque token. The net doesn't need to have seen "bears" in training to reason about bears.</li> <li>Enables <strong>graceful ignorance</strong>: if the net doesn't have a compiled subnet for a particular entity (e.g., "are bears mortal?"), it can recognize that it lacks the relevant syllogism and use an opaque token in its reply to express "I don't know if bears are mortal" rather than hallucinating.</li> <li>The compiled portion becomes a <strong>logical skeleton</strong> that the statistical portion fills with content.</li> </ul>
<p><strong>Status:</strong> CONCEPTUAL. No implementation yet. Requires: (1) the compiled net to actually exist, (2) an execution model that tracks token flow through compiled weights, (3) the substitution mechanism at output.</p>
<p>---</p>
<h2>Syllogism Presentation as Training</h2>
<p><strong>Core idea:</strong> Present syllogisms to the net in natural language ("all cats are mammals"), and the net compiles that syllogism and dynamically adds it to its weights.</p>
<p>This means <strong>presenting syllogisms IS a training approach</strong> — but fundamentally different from gradient-based training: <ul> <li>No loss function. No backpropagation. No epochs.</li> <li>Compilation is deterministic: same syllogism always produces same weights.</li> <li>Adding a syllogism doesn't disturb existing knowledge (no catastrophic forgetting).</li> <li>Each fact is independently addressable (can remove "all cats are mammals" without affecting "all dogs are mammals").</li> </ul>
<p><strong>Example flow:</strong> <code></code>` Input: "all bears are mammals, all mammals are mortal"   → parse into syllogistic form (Barbara: A-a-A)   → map to NPN class / Boolean function   → compile to DKC weights   → add to compiled weight region   → net can now answer "are bears mortal?" → yes (via compiled pathway) <code></code>`</p>
<p><strong>Status:</strong> CONCEPTUAL. Depends on: Gap 2 (syllogism → Boolean mapping), deterministic NL parser (see below), dynamic weight insertion mechanism.</p>
<p>---</p>
<h2>Wired Integration (Not Pipelining)</h2>
<p><strong>Critical architectural point:</strong> The compiled DKC portion and the traditional trained portion are NOT two separate models with a token-level interface between them. They are <em></em>literally wired together into a single set of weights with connected pathways.<em></em></p>
<p>This is not: <code></code>` compiled_net(input) → tokens → trained_net(tokens) → output    ← NO, not this <code></code>`</p>
<p>This is: <code></code>` single hybrid net where some weight regions are compiled (exact, from DKC) and some weight regions are trained (statistical, from corpus), with shared pathways between them <code></code>`</p>
<p><strong>Why this matters:</strong> <ul> <li>Pipeline approaches lose information at the token bottleneck between stages.</li> <li>Wired integration means the compiled weights influence activation patterns throughout the network, not just at a handoff point.</li> <li>The statistical regions can "lean on" the compiled structure during inference.</li> </ul>
<p><strong>The acceleration thesis:</strong> Having compiled syllogisms as part of the net's weights will help the "traditional" trained regions become smarter much more rapidly on an extremely small training corpus. The compiled structure provides scaffolding — logical relationships that the statistical training doesn't need to discover from data because they're already in the weights.</p>
<p><strong>If we can decompile traditional LLMs to knots</strong> (reverse DKC, Demos 26-28), we should be able to wire compiled and trained portions together — because both are expressible in the same algebraic framework (bracket values / cyclotomic integers).</p>
<p><strong>Status:</strong> HIGHLY SPECULATIVE. Requires: reverse DKC to actually work cleanly (it doesn't yet — phase decoherence problem from <a href="../inventory/entries/demo_46.html">D46</a>), a compatible weight format, and an integration architecture.</p>
<p>---</p>
<h2>Deterministic Natural Language Parser</h2>
<p><strong>Requirement:</strong> To feed syllogisms into the compiled net, we need a framework for deterministic natural language parsing that converts natural language into the right token/opaque-token structure.</p>
<p><strong>Development path:</strong> 1. Start simple: classic syllogistic grammar. "Aristotle is a man."    "All men are mortal." Subject-copula-predicate forms. 2. Extend to more complex syllogistic structures: hypothetical syllogisms,    disjunctive syllogisms, sorites (chains). 3. Eventually: parse a paragraph of natural language text into a data structure    ready to feed into the compiled net's token/opaque-token format.</p>
<p><strong>Connection to rhubarb:</strong> We already have a parser generator (lapifex) and C89 string libraries (chorda). A deterministic syllogism parser is a natural rhubarb library. This could be one of the first pieces of the pipeline that actually gets built.</p>
<p><strong>Status:</strong> NOT STARTED. But the tools exist in rhubarb to build it.</p>
<p>---</p>
<h2>Key Gaps (Ordered by Dependency)</h2>
<h3>Gap 1: Taxonomy → Braid Encoding</h3>
How do you take a taxonomic/syllogistic structure and produce a braid whose
bracket value encodes the right logical operation? This is the biggest unknown.
<p>Suggestive connections: <ul> <li>TL diagrams are planar matchings (pairings). Taxonomic categories group things.</li> <li>The braid group connects to partial orders and lattice structures. A taxonomy IS a partial order.</li> <li>Refinement of set partitions (coarser → finer categories) has lattice structure that might map to the TL lattice.</li> <li>Classical syllogisms are 3-term logical operations. DKC handles 3-input Boolean functions. Natural fit in dimensionality.</li> </ul>
<p>Status: UNEXPLORED. Needs a dedicated investigation (demo or research arc).</p>
<h3>Gap 2: Syllogism → Boolean Function Mapping</h3>
Can the 24 valid syllogistic forms be mapped to specific NPN classes? This
is potentially answerable with existing tools — enumerate the syllogistic
forms, express each as a truth table, classify by NPN equivalence, check
which ones DKC can compile.
<p>Status: APPROACHABLE. Could be a single demo.</p>
<h3>Gap 3: Multi-Layer DKC Composition</h3>
Can the output of one DKC neuron feed into another while maintaining exactness?
<a href="../inventory/entries/demo_19.html">Demo 19</a> showed cascade thresholding works (collapse to bit at each stage).
The richer question: can you pass the full complex value through?
<p>Status: PARTIALLY EXPLORED (<a href="../inventory/entries/demo_19.html">Demo 19</a> cascade). Full complex composition UNTESTED.</p>
<h3>Gap 4: Integration Architecture</h3>
How do compiled weights coexist with trained weights in the same model?
The answer (per vision discussions): NOT pipelining. Literally wired together
at the weight level. Compiled regions and trained regions share pathways.
<p>Key sub-questions: <ul> <li>What does "wired together" mean concretely? Shared activation layers? Compiled neurons in the same layer as trained neurons?</li> <li>How does the opaque token mechanism interact with attention?</li> <li>Can reverse DKC (<a href="../inventory/entries/demo_26.html">D26</a>-<a href="../inventory/entries/demo_28.html">28</a>) provide the bridge format for integration?</li> <li>What's the right loss function for the trained portion that respects the compiled structure?</li> </ul>
<p>Status: CONCEPTUAL. The architectural direction is clearer (wired, not pipelined) but implementation details are unexplored.</p>
<h3>Gap 5: Dynamic Recompilation</h3>
Can you update compiled weights fast enough for "dynamic" to be meaningful?
DKC compilation is currently exhaustive search over a finite catalog — fast
for 3 inputs (~100^4 = 100M, seconds), unclear for larger inputs.
<p>Status: DEPENDS ON scaling (Gap 6).</p>
<h3>Gap 6: Scaling Beyond 3 Inputs — FURTHER RESOLVED (<a href="../inventory/entries/demo_76.html">D76</a>-<a href="../inventory/entries/demo_82.html">D82</a>)</h3>
<a href="../inventory/entries/demo_63.html">Demo 63</a> extended DKC to 4-input (k=8, 96 solutions) and 5-input (k=15, 3020
solutions) parity, establishing the parity ceiling at n=5 for Z[zeta_8]. The
triskelion generalization (k=2n) was FALSIFIED; the true scaling law is
k=2M-1 where M is the ray count.
<p><a href="../inventory/entries/demo_65.html">Demo 65</a> confirmed Z[zeta_16] does NOT raise the parity ceiling — it stays at n=5 (tier thresholds identical: XOR3 k=6, XOR4 k=8, XOR5 k=14). The gap-of-2 hypothesis was REFUTED: pigeonhole rises from 7 to 14 but actual ceiling stays at 5, widening the gap to 9. This supports the Conjecture (Universal Ceiling) that the n=5 bound is topological, not algebraic.</p>
<p>For the original vision, this meant: <ul> <li><strong>Individual DKC neurons handle up to 5-input parity</strong> (the hardest function). Simpler functions (AND, OR, MAJ) likely have higher ceilings.</li> <li><strong>3-input syllogisms are well within capacity</strong> — the natural fit between syllogisms and DKC is confirmed by the n=5 ceiling.</li> <li><strong>Larger functions require composition</strong> — multi-layer DKC (Gap 3) was thought to be the path for anything beyond 5 inputs.</li> <li><strong>The ceiling is algebra-independent</strong> — Z[zeta_16] and Z[zeta_8] agree exactly. The wall appears to be topological.</li> </ul>
<p><strong>UPDATED — <a href="../inventory/entries/demo_76.html">D76</a>-<a href="../inventory/entries/demo_82.html">D82</a> substantially revised this picture:</strong></p>
<p><a href="../inventory/entries/demo_77.html">D77</a> showed that XOR8 IS solvable at ζ₈ with S¹×S² product activation (Sec(8)×Voronoi, 112 cells, 6 solutions). The n=5 ceiling was activation-specific: it was the S¹-only sector activation that capped at XOR5, not the root of unity. <a href="../inventory/entries/demo_78.html">D78</a> then confirmed that XOR10 = 0 at ζ₈ even with Sec×Vor activation — ζ₈ is a finite group (24 elements, binary octahedral, E₇) and its combinatorial catalog diversity is genuinely exhausted at XOR8.</p>
<p><a href="../inventory/entries/demo_79.html">D79</a> broke through the ζ₈ ceiling by switching to ζ₁₂ (infinite group): XOR10 = 124 winners, XOR12 = 50+ winners. The finite-vs-infinite group distinction is the key variable, not the subscript on ζ.</p>
<p><a href="../inventory/entries/demo_82.html">D82</a> identified the <em></em>fundamental variable governing XOR capacity: crossing depth<em></em>. The linear depth law is:</p>
<p><code></code>` max_xor ≈ depth + 6 <code></code>`</p>
<p>Each unit of crossing depth (= generator multiplications = braid crossings) adds a fixed increment to computational capacity. The <a href="../inventory/entries/demo_81.html">Demo 81</a> logarithmic law (0.62 XOR per doubling of catalog size at ζ₁₂) is a corollary: catalog grows as ~2^depth, so log₂(catalog) ≈ depth, giving max_xor ≈ 0.62 × log₂(catalog). The logarithmic law was an artifact of exponential catalog growth — depth is the real variable.</p>
<p><a href="../inventory/entries/demo_82.html">D82</a> also demonstrated <strong>algebraic coherence beats raw vocabulary</strong>: a deep subset of 564 entries (fewer directions, fewer angles) outcomputes a strided subset of 564 entries with maximum vocabulary coverage, reaching XOR12 vs XOR10. The determining factor is shared intermediate products from generator multiplication chains — deep entries carry algebraic coherence, not just geometric coverage.</p>
<p><strong>Revised vision implications:</strong></p>
<ul>
<li><strong>ζ₈ (finite group, 24 elements, E₇)</strong>: ceiling at XOR8 with S¹×S² activation. The ADE classification identifies this as the binary octahedral group. Quantum dimension [2]_q vanishes at ζ₈ — this is the most singular point of quantum group parameter space.</li>
<li><strong>ζ₁₂ (infinite group)</strong>: XOR12 reachable with ~1140-entry catalog; XOR14 predicted at ~38K entries. Capacity grows logarithmically with catalog size.</li>
<li><strong>Depth law: max_xor ≈ depth + 6</strong>: the deepest entries (8 generator multiplications deep) are 2× more efficient than shallow or strided entries at equal count. More complex knots = more computational power.</li>
<li><strong>Implication for multi-layer DKC (Gap 3)</strong>: multi-layer composition may not be needed if deep infinite-group catalogs can reach high XOR targets directly in a single neuron. The architectural question shifts from "how do we compose neurons?" to "what is the right depth profile for the catalog?"</li>
</ul>
<p>Status: ζ₈ ceiling confirmed at XOR8. ζ₁₂ breaks the wall with logarithmic/ depth-linear scaling. The fundamental capacity variable is crossing depth, not catalog vocabulary or root-of-unity subscript.</p>
<h3>Gap 7: The Wall Is Two-Layered — NEW (<a href="../inventory/entries/demo_65.html">D65</a>)</h3>
<p>The XOR6 wall has two distinct layers that require different tools:</p>
<ul>
<li><strong>Absolute geometric wall (k≤23)</strong>: No binary partition of any number of sectors (for any k≤23) can separate the XOR6 truth table using Z[zeta_8] weights. PROVEN exhaustively. This is a topological obstruction — the self-doubling impossibility theorem (<a href="../inventory/entries/demo_64.html">D64</a>) and the matroid minor chain structure (<a href="../inventory/entries/demo_64.html">D64</a>) explain WHY the wall exists. The minimum Hamming distance from any 6-weight candidate to XOR6 is d=4, with no candidate achieving d=0,1,2,3.</li>
</ul>
<ul>
<li><strong>Convention wall (standard labeling fails, custom succeeds)</strong>: At k=24, generalized binary labelings (not just standard odd/even) break through. Exactly 3 of 2700 candidate pairs admit XOR6 at k=24. The standard odd/even convention used since Aizenberg is one specific choice; relaxing it reveals that the hard wall is at k&lt;=23, not at all k.</li>
</ul>
<p><strong>Implication for the hybrid LLM</strong>: When designing compiled DKC neurons, the activation function design matters. The standard odd/even convention may not be optimal; the principled approach is to derive the activation from the underlying geometry (Voronoi cells on S²) rather than treating it as a fixed convention.</p>
<p>Status: Two-layer structure PROVEN. The convention wall is now understood as an activation design choice, not a fundamental limit.</p>
<h3>Gap 9: Finite vs. Infinite Group Choice — NEW (<a href="../inventory/entries/demo_80.html">D80</a>)</h3>
<p><a href="../inventory/entries/demo_80.html">D80</a> established that under the standard two-generator construction, only ζ₄ and ζ₈ generate finite SU(2) subgroups. All other tested roots (ζ₆, ζ₁₀, ζ₁₂, ζ₁₆, ζ₂₀) generate infinite groups. The boundary is non-monotonic: ζ₆ is infinite despite sitting between the two finite cases.</p>
<p><strong>The two computational regimes:</strong></p>
<ul>
<li><strong>Finite-group roots (ζ₄, ζ₈)</strong>: structured, small catalog with complete algebraic closure; every entry has an exact place in the ADE classification (ζ₄ → Binary Dihedral Q₈, ζ₈ → Binary Octahedral E₇); hard capacity ceiling because combinatorial diversity is genuinely exhausted. At ζ₈, the quantum dimension [2]_q = q + q⁻¹ = i + (-i) = 0: this is the most singular point in quantum group parameter space, where the TL category becomes maximally non-semisimple. The computation is tractable (Kuperberg: lattice roots are outside the #P-hard regime).</li>
<li><strong>Infinite-group roots (ζ₁₂, ζ₁₀, ζ₁₆, ...)</strong>: catalog grows without bound; capacity scales logarithmically with catalog size (depth-linearly with crossing depth); no hard ceiling within feasible search. These roots approach dense subgroups of SU(2) — the directions eventually cover S² uniformly.</li>
</ul>
<p><strong>The architecturally fundamental question:</strong></p>
<p>Can you get the best of both worlds — the structural guarantees of a finite group (every entry has an exact algebraic meaning; catalog is fully characterizable; computation is provably tractable) combined with the scaling capacity of an infinite group (no ceiling; depth drives power)?</p>
<p>Possible directions: <ul> <li><strong>Union catalog</strong> (ζ₈ + ζ₁₂): the two groups are largely non-overlapping (only 12% quaternion overlap, 15% direction overlap by <a href="../inventory/entries/demo_79.html">D79</a>). A union might combine finite-group structural guarantees for the ζ₈ component with infinite-group capacity for the ζ₁₂ component. Whether this provides superadditive capacity is an open question.</li> <li><strong>Finite substructure extraction</strong>: even within an infinite group, there may be finite sub-catalogs with desirable structural properties (e.g., all entries up to depth d form a well-characterized set). The depth law (<a href="../inventory/entries/demo_82.html">D82</a>) already shows these subsets have predictable capacity.</li> <li><strong>ADE gaps</strong>: ~~E₈ (binary icosahedral, 120 elements) NOT reached.~~ <strong>RESOLVED by <a href="../inventory/entries/demo_94.html">D94</a></strong>: 2I (E₈) reached via explicit Z[sqrt5] generators (s = (1+i+j+k)/2, t = (phi + phi_inv*i + j)/2). Capacity confirmed higher than z8 at matched size; solvability bottleneck validated. E₆ (binary tetrahedral, 24 elements) is still NOT reached by any natural construction.</li> </ul>
<p><strong>Power-of-two finiteness conjecture (<a href="../inventory/entries/demo_80.html">D80</a>):</strong> ζ₂ₖ for k ≥ 1 (i.e., ζ₄, ζ₈, ζ₁₆, ζ₃₂, ...) may all be finite under this construction. <a href="../inventory/entries/demo_80.html">D80</a> confirmed the first two; ζ₃₂ is the next test.</p>
<p>Status: Two-regime structure established. <a href="../inventory/entries/demo_94.html">D94</a> resolved the E₈/2I ADE gap and confirmed solvability as the capacity bottleneck (Barrington). Union catalog, E₆ gap, and power-of-two conjecture remain active research directions.</p>
<h3>Gap 10: Encoding Design — NEW (<a href="../inventory/entries/demo_92.html">D92</a>)</h3>
<p><a href="../inventory/entries/demo_92.html">D92</a> proves that the +/-q input encoding is structurally parity-locked: masks 0...0 and 1...1 always produce identical quaternion sums (both zero), so any function where f(0...0) != f(1...1) is impossible under ANY activation. This means AND, OR, MAJ, THRESHOLD — every standard Boolean function except XOR/XNOR — have exactly zero winners at all depths, all resolutions, all roots of unity.</p>
<p>The encoding is more fundamental than the activation, the catalog, or the root of unity. It determines which Boolean functions are computable AT ALL. The design hierarchy is now:</p>
<p><code></code>` Encoding  →  determines which functions are computable   Activation  →  determines how many solutions exist (resolution)     Catalog depth  →  determines maximum arity       Root of unity  →  determines capacity ceiling (finite vs infinite) <code></code>`</p>
<p>The 1wpi (one-weight-per-input) encoding from <a href="../inventory/entries/demo_48.html">D48</a>/<a href="../inventory/entries/demo_50.html">D50</a> computes all 13 NPN classes — so DKC is NOT parity-locked, only the +/-q encoding is. But the 1wpi encoding has not been tested for depth-law behavior. Key sub-questions:</p>
<ul>
<li>Does max_and or max_maj scale linearly with depth under 1wpi?</li>
<li>If so, what is the slope? (Parity's slope is ~1 under +/-q.)</li>
<li>Can hybrid encodings (some inputs +/-q, some 1wpi) balance function breadth with depth-law scaling?</li>
<li>Is the +/-q encoding provably optimal for parity among all 2-bit-per-weight encodings?</li>
</ul>
<p>For the hybrid LLM vision, syllogistic logic requires AND, OR, and implication — not just XOR. The encoding must be designed to support these functions. The 1wpi encoding is the current candidate, but its scaling behavior is the most urgent open question for the compilation pipeline.</p>
<p>Status: PARITY-LOCK PROVED (<a href="../inventory/entries/demo_92.html">D92</a>). 1wpi depth-law behavior UNTESTED. This is the most architecturally consequential gap identified since <a href="../inventory/entries/demo_50.html">D50</a>.</p>
<h3>Gap 8: Quaternionic DKC and the Bloch Sphere — NEW (<a href="../inventory/entries/demo_66.html">D66</a>-<a href="../inventory/entries/demo_71.html">D71</a>)</h3>
<p><a href="../inventory/entries/demo_66.html">D66</a>-<a href="../inventory/entries/demo_71.html">D71</a> opened a wholly new dimension: the computation lives on S² (the Bloch sphere / rotation axis direction), not on S¹ (complex circle) or S³ (full unit quaternion). This is not a minor generalization — it changes the geometry of DKC entirely.</p>
<p>Key discoveries: <ul> <li>Kauffman braid representations in SU(2) produce exactly the 24 vertices of the 24-cell (binary octahedral group). The bracket and quaternion are complementary projections of the same braid group representation.</li> <li>The Hopf fibration S³ → S² is respected: the Hopf fiber (phase ξ₁) is computationally INERT — it carries zero DKC information at all resolutions tested. The computation lives entirely on the S² Hopf base (eigenvector directions, i.e., the rotation axis).</li> <li>The natural computational object is the 13-direction eigenvector Voronoi on S². 14 cells suffice for 36 XOR6 solutions — more than the 25-cell S³ Voronoi (35 solutions) or the 25-cell S¹ approach.</li> <li>The 13=13 theorem (<a href="../inventory/entries/demo_71.html">D71</a>): minimum bandwidth l=6 exactly because 2×6+1=13 equals the number of eigenvector directions. This is the cleanest theoretical result yet.</li> </ul>
<p><strong>Implication for the hybrid LLM</strong>: DKC neurons can be understood as computing on the Bloch sphere S²=CP¹, the state space of a qubit. This connects compiled DKC weights directly to quantum information theory — the 13-direction Voronoi may correspond to a specific quantum measurement basis. Whether this connection is formal or merely structural is an open research question.</p>
<p>Status: ACTIVE RESEARCH FRONTIER. Multiple open questions across <a href="../inventory/entries/demo_66.html">D66</a>-<a href="../inventory/entries/demo_71.html">D71</a>.</p>
<p>---</p>
<h2>Near-Term Explorations (Next Few Demos)</h2>
<p>1. <strong>Syllogism → NPN mapping</strong> — Enumerate 24 valid syllogistic forms, express    as truth tables, classify by NPN, check DKC compilability. Single demo.    Would confirm or deny the natural fit between syllogisms and 3-input DKC.</p>
<p>2. <strong>Multi-layer composition test</strong> — Feed DKC neuron output into another DKC    neuron. Test both cascade-threshold (<a href="../inventory/entries/demo_19.html">Demo 19</a> style) and full-complex-value    passing. Single demo.</p>
<p>3. ~~<strong>4-input DKC</strong> (<a href="../inventory/entries/demo_63.html">Demo 63</a>, already planned)~~ — <strong>DONE</strong> (<a href="../inventory/entries/demo_63.html">Demo 63</a>).    4-input parity at k=8 (96 solutions), 5-input at k=15 (3020 solutions),    parity ceiling n=5, triskelion FALSIFIED, oriented matroid classification.</p>
<p>~~<strong>Parity matroid recursion</strong> (<a href="../inventory/entries/demo_64.html">Demo 64</a>)~~ — <strong>DONE</strong>. Funnel-shaped matroid    minor chain, self-doubling impossibility theorem, two-layer wall anatomy.</p>
<p>~~<strong>Clifford staircase / Z[zeta_16]</strong> (<a href="../inventory/entries/demo_65.html">Demo 65</a>)~~ — <strong>DONE</strong>. Parity ceiling    algebra-independent. Two-layer wall structure. Generalized XOR6 at k=24.</p>
<p>~~<strong>Quaternionic DKC</strong> (Demos 66-71)~~ — <strong>DONE</strong>. 24-cell emergence, Hopf    inertness, S² as computational home, 13-direction Voronoi, 13=13 spectral    theorem, musical mapping, direction nesting theorem, stereographic proof of    intrinsic curvature.</p>
<p>4. <strong>Toy taxonomy → weight pipeline</strong> — Take a 5-node taxonomy, manually encode    as braids (even if the encoding is ad hoc), compile to DKC weights, verify    logical inference works end-to-end. Proof of concept, not general solution.</p>
<p>5. <strong>Deterministic syllogism parser</strong> — Using lapifex/chorda, build a parser    that converts "All X are Y" / "Aristotle is a man" forms into structured    representations with opaque token slots. First rhubarb library in the    vision pipeline.</p>
<p>6. <strong>Opaque token flow demo</strong> — Take a compiled syllogism, feed it input with    opaque tokens (e.g., subject=OPAQUE_1, predicate=OPAQUE_2), verify the net    produces correct logical output with opaque tokens in the right positions,    then substitute back to get the natural language answer.</p>
<p>7. <strong>ζ₁₂ with Sec×Vor activation</strong> — <a href="../inventory/entries/demo_77.html">D77</a> showed Sec(8)×Voronoi unlocks    XOR8 at ζ₈. <a href="../inventory/entries/demo_79.html">D79</a>/<a href="../inventory/entries/demo_82.html">D82</a> showed ζ₁₂ reaches XOR12 with the same activation    family. The combination has not been rigorously tested: apply <a href="../inventory/entries/demo_77.html">D77</a>'s    activation-zoo methodology to ζ₁₂ to find the minimum k for XOR10 and    XOR12 and confirm the activation determines capacity principle holds at the    infinite-group scale.</p>
<p>8. <strong>ζ₃₂ finiteness test</strong> — <a href="../inventory/entries/demo_80.html">D80</a>'s power-of-two conjecture predicts ζ₃₂    (θ = π/16) generates a finite SU(2) subgroup. A single test_root(32)    call would confirm or refute. If finite, it would be a new ADE-type member    between E₇ (ζ₈) and potentially E₈ territory, with its own capacity    ceiling higher than ζ₈ but tractable.</p>
<p>9. <strong>Direct deep-entry generation at ζ₁₂</strong> — <a href="../inventory/entries/demo_82.html">D82</a>'s key insight: deep entries    (depth ≥ 6) are twice as efficient as shallow or strided entries at the same    count. But the current approach generates them by building the full BFS    closure through all shallower rounds. <a href="../inventory/entries/demo_82.html">D82</a> asks: can depth-d entries be    generated directly from their algebraic properties (shared intermediate    products, angular refinement structure) without computing all shallower    depths? This would make ζ₁₂'s high-XOR regimes computationally accessible    without exponential catalog growth.</p>
<p>10. ~~<strong>Indecomposability parameter b calculation</strong> (<a href="../inventory/entries/demo_85.html">D85</a> seed)~~ — <strong>DONE</strong>     (<a href="../inventory/entries/demo_85.html">Demo 85</a>). b = -5/8 confirmed at TL_4 via leading-coefficient extraction     from delta-parameterized Markov trace on the full regular representation.     The "controversy" (b = -2 vs b = -5/8) dissolved: different normalization     conventions. b is a collective property of the full algebra (<a href="../inventory/entries/demo_86.html">Demo 86</a>     established that single P_{0,0} universally diverges).</p>
<p>11. ~~<strong>Dense polymer fusion rules</strong> (<a href="../inventory/entries/demo_86.html">D86</a> seed)~~ — <strong>PARTIALLY ADDRESSED</strong>     (<a href="../inventory/entries/demo_86.html">Demo 86</a>). The delta-parameterized approach on single projective covers     universally diverges — a novel negative result. The multiplicity from the     full regular representation is structurally essential. The actual fusion     rule verification remains open; the method must be different from the     delta-parameterized Gram matrix approach.</p>
<p>12. <strong>1wpi encoding depth law</strong> (<a href="../inventory/entries/demo_92.html">D92</a> seed) — The most architecturally urgent     question. The +/-q encoding is parity-locked (<a href="../inventory/entries/demo_92.html">D92</a>). The 1wpi encoding     computes all 13 NPN classes (<a href="../inventory/entries/demo_48.html">D48</a>/<a href="../inventory/entries/demo_50.html">D50</a>) but its depth-law behavior is     unknown. Does max_and or max_maj scale linearly with depth under 1wpi?     If yes, what slope? If no, the entire compilation cost model for     non-parity functions is open. Single demo, high leverage.</p>
<p>13. <strong>Encoding space exploration</strong> (<a href="../inventory/entries/demo_92.html">D92</a> seed) — Systematic survey of encodings     between +/-q (paired, parity-only) and 1wpi (independent, all functions).     How many bits per weight? Which pairing structures? What equivalence     classes does each encoding produce? Goal: map the encoding design space     and identify the right encoding for syllogistic logic (AND, OR,     implication). 1-2 demos.</p>
<p>14. <strong>Balanced exponentials formal proof</strong> (<a href="../inventory/entries/demo_91.html">D91</a> seed) — The linear depth law     slope arises from BFS branching factor (~2×/round) vs parity demand growth     (4×/weight). An analytical derivation connecting these two exponentials     would upgrade the balanced exponentials conjecture to a theorem (P05).     The BFS branching factor depends on the group structure; the parity demand     growth is combinatorial. Single demo, clean formal proof candidate.</p>
<p>15. <strong>Regime transition threshold</strong> (<a href="../inventory/entries/demo_87.html">D87</a> seed) — <a href="../inventory/entries/demo_87.html">D87</a> established the two     regimes (nulls critical at ζ₈, dispensable at ζ₁₂). The exact transition     point is unknown. Testing at intermediate catalog sizes (truncated ζ₁₂,     ζ₁₀) would locate the threshold. Is it a specific direction count, null     fraction, or catalog size? A sharp threshold would give a concrete design     criterion. Single demo.</p>
<p>16. <strong>Relational activation function</strong> (<a href="../inventory/entries/demo_90.html">D90</a> seed) — Current activations     (sector, Voronoi, combined) treat entries independently. <a href="../inventory/entries/demo_90.html">D90</a> proves the     depth law mechanism is relational (axis cancellation between entries). An     activation function that explicitly uses axis dot products between entries     in a tuple (rather than classifying entries individually) might break the     linear depth law and achieve superlinear scaling. Speculative but     potentially high-impact. 1-2 demos.</p>
<p>17. ~~<strong><a href="../inventory/entries/demo_95.html">D95</a>: RKHS kernel rank test</strong> (<a href="../inventory/entries/demo_94.html">D94</a> seed)~~ — <strong>REPURPOSED</strong>. <a href="../inventory/entries/demo_95.html">D95</a> became     the commutator depth and cross-layer synergy demo instead. The RKHS kernel     test remains valuable but has not been executed. Original plan: compute DKC     kernel K(m,m') = quaternion inner product of signed sums for 2I vs z8.</p>
<p>18. <strong>Higher k_sec with 2I</strong> (<a href="../inventory/entries/demo_94.html">D94</a> seed) — <a href="../inventory/entries/demo_94.html">D94</a> used k_sec=12 (384 cells).     2I has 9 half-angles and 31 directions — richer than z8. k_sec=24 doubles     cells to ~768. Quick test: does N=8 XOR become nonzero? If yes, the     pigeonhole wall is activation-tunable, not structural. Single parameter     change.</p>
<p>19. <strong>Depth law under phase_cell</strong> (<a href="../inventory/entries/demo_93.html">D93</a> seed) — <a href="../inventory/entries/demo_93.html">D93</a> showed phase_cell     recovers all 13 NPN classes and reveals circuit complexity hierarchy. The     depth law was established under combined_cell. Does the linear relationship     hold under phase_cell? Different functions may have different slopes —     a richer depth-law landscape. Single demo.</p>
<p>20. <strong>Quantum dimension direct test at Fibonacci parameter</strong> (<a href="../inventory/entries/demo_94.html">D94</a> seed) —     Test at q = e^{2<em>pi</em>i/5} directly rather than through 2I. [2]_q = phi^{-1}     ~ 0.618 at this parameter — the "maximally computational" TQC point     (Mochon 2003). How does a dense catalog here compare to 2I's finite one?     Bridges TQC and DKC most directly. 1-2 demos.</p>
<p>21. <strong>Cross-depth 2I analysis</strong> (<a href="../inventory/entries/demo_94.html">D94</a> seed) — 2I BFS depth profile is a     symmetric diamond (5,8,11,12,11,8,4,1). Does the contribution profile     mirror the symmetry, or are deep entries disproportionately valuable as     at z12 (<a href="../inventory/entries/demo_82.html">D82</a>)? Tests depth law applicability to non-solvable finite groups.     Single demo.</p>
<p>22. ~~<strong>6-strand W_{6,4} decisive test</strong> (<a href="../inventory/entries/demo_101.html">D101</a> seed)~~ — <strong>DONE</strong> (<a href="../inventory/entries/demo_102.html">Demo 102</a>).     Growth ~5x CONFIRMED at n=6 (matching prediction), extending the sl_d     functor thesis to 4 consecutive strand counts: ~2.2x (n=3), ~3.1x (n=4),     ~4x (n=5), ~5x (n=6). All three n=6 modules (W_{6,0}, W_{6,2}, W_{6,4})     produce BIT-FOR-BIT IDENTICAL BFS depth profiles — BFS growth is a braid     group invariant, not a module property. The radical in W_{6,4} carries an     abelian writhe character (Barrington-Radical Principle); simple W_{6,0}     beats non-simple W_{6,4} at every XOR level.</p>
<p>23. <strong>Radical content vs XOR correlation study</strong> (<a href="../inventory/entries/demo_100.html">D100</a> seed) — <em></em>PARTIALLY     RESOLVED<em></em> (<a href="../inventory/entries/demo_102.html">Demo 102</a>). <a href="../inventory/entries/demo_102.html">D102</a>'s Barrington-Radical Principle proves the     radical carries an abelian character (provably useless for parity). At     matched dimension (W_{6,0} vs W_{6,4}, both dim=5), the simple module     WINS at every XOR level. The radical is inert — but the mixing row in     non-semisimple modules still provides an 8% XOR6 boost (<a href="../inventory/entries/demo_102.html">D102</a>), suggesting     the extension structure matters even though the radical direction does not.     The Casimir question from <a href="../inventory/entries/demo_100.html">D100</a> (1.36x-1.86x correlation) vs <a href="../inventory/entries/demo_101.html">D101</a> (Casimir     INVERSION in simple modules) remains unresolved: test on W_{4,3} would     determine whether Casimir polarity depends on module simplicity. 1 demo.</p>
<p>24. <strong>Multi-strand activation zoo</strong> (<a href="../inventory/entries/demo_99.html">D99</a> seed) — <a href="../inventory/entries/demo_99.html">D99</a> used sector activation     on individual matrix entries. Richer activations (Frobenius norm sectors,     eigenvalue sectors, determinant sectors) may access different computational     regimes. The readout bottleneck (trace=0 XOR at 3-strand) shows that     activation/readout design is the critical frontier. Systematic survey of     readout × activation combinations. 2-3 demos.</p>
<p>25. <strong>Fibonacci parameter direct test</strong> (<a href="../inventory/entries/demo_94.html">D94</a> seed) — Test at q = e^{2πi/5}     where [2]_q = φ^{-1} ≈ 0.618, the Fibonacci/Jones-Wenzl point that is     "maximally computational" for TQC (Mochon 2003). Compare dense catalog     structure to 2I's finite catalog. If the Fibonacci point produces a clean     finite group with universal computation, it bridges TQC and DKC most     directly. 1-2 demos.</p>
<p>26. <strong>Artificial perfect cell construction</strong> (<a href="../inventory/entries/demo_96.html">D96</a>-<a href="../inventory/entries/demo_97.html">D97</a> seed) — <a href="../inventory/entries/demo_96.html">D96</a> showed Cell B     (null-derived, non-commutator) achieves 100% XOR at every N. <a href="../inventory/entries/demo_97.html">D97</a> proved     this is geometric inevitability from orthogonal-frame structure with a     50-degree robust plateau. Can artificial catalogs be constructed that     reproduce Cell B's geometry WITHOUT the BFS enumeration? If so, DKC     compilation can bypass BFS entirely for this cell type. Single demo.</p>
<p>27. <strong>Non-semisimple TQFT DKC formalization</strong> (<a href="../inventory/entries/demo_99.html">D99</a> seed) — <a href="../inventory/entries/demo_99.html">D99</a>'s Ext^1     catalytic preparation thesis is empirical. The connection to Gainutdinov-     Read-Saleur non-semisimple TQFT is structural but not formal. A rigorous     formulation connecting TL module Ext^1 groups to DKC algebraic regime     capacity would be a major theoretical result and potential paper core.     Theory-heavy, 1-2 demos plus formal writeup.</p>
<p>28. <strong>Encoding-dependent catalog optimization</strong> (<a href="../inventory/entries/demo_108.html">D108</a>-<a href="../inventory/entries/demo_109.html">D109</a> seed) — <a href="../inventory/entries/demo_108.html">D108</a>-<a href="../inventory/entries/demo_109.html">D109</a>     establish that product closure polarity INVERTS between additive and     multiplicative encodings. A parity-capable catalog under additive encoding     (high product closure, connected graph) is structurally different from a     parity-capable catalog under multiplicative encoding (low product closure,     products escape vocabulary). Can Raqiya pre-screen candidate catalogs for     the appropriate encoding? Can it predict WHICH encoding will work better     for a given value vocabulary? Single demo, high leverage for the     compilation pipeline.</p>
<p>29. <strong>Raqiya deployment at ζ₁₂</strong> (<a href="../inventory/entries/demo_109.html">D109</a> seed) — Raqiya's diagnostic power has     been demonstrated exclusively at ζ₈ (finite group, 100 values) and ζ₁₆     (delta=sqrt(2), finite/enriched). At ζ₁₂ (infinite group, 4096 entries),     the algebra is structurally richer — <a href="../inventory/entries/demo_109.html">D109</a>'s j=0 liveness observation     suggests Raqiya may not be able to discriminate at all (structural     universality when j=0 sector is alive). Testing Raqiya at ζ₁₂ would     establish the tool's operational range: does it diagnose impoverishment     (useful) or health (tautological)? Single demo.</p>
<p>30. <strong>j=0 liveness conjecture</strong> (<a href="../inventory/entries/demo_109.html">D109</a> seed) — <a href="../inventory/entries/demo_109.html">D109</a> observes that at     delta=sqrt(2), where the j=0 TL sector is alive (non-zero quantum     dimension), Raqiya cannot discriminate parity from non-parity: the     algebra is so rich that all structural prerequisites are satisfied     trivially. Conjecture: j=0 liveness implies structural universality     (all function classes achievable with sufficient activation resolution).     Test at delta=sqrt(3), delta=sqrt(5), and other non-zero delta values     where j=0 is alive. Would establish a necessary condition for DKC     structural limitations. 1-2 demos.</p>
<p>31. <strong>Amy bridge formalization</strong> (<a href="../inventory/entries/demo_108.html">D108</a> seed) — The T-gate/Hadamard     correspondence with DKC's product closure / v_2 connectivity is     structural (<a href="../inventory/entries/demo_108.html">D108</a>). A formal reduction would compute the sde (smallest     denominator exponent, Amy 2023) for each DKC catalog entry and correlate     sde with parity capability. If low-sde entries cluster in the parity     vocabulary and high-sde in the poison vocabulary, the quantum circuit     synthesis resource hierarchy directly explains DKC capability. Single     demo, potentially paper-quality result.</p>
<p>32. <strong>TL visibility filter formal proof</strong> (<a href="../inventory/entries/demo_106.html">D106</a> seed) — <a href="../inventory/entries/demo_106.html">D106</a> demonstrated     that properties surviving the TL quotient (writhe) correlate with DKC     output while properties killed by it (entropy, Burau spectral radius)     do not. The structural argument (e_i^2=0 kills expanding eigenvalues)     is clean enough for a formal proof (P05 candidate). This would be the     first proof that constrains which FEATURES of braids are computationally     relevant — a selection principle for catalog engineering. Theory demo.</p>
<p>33. <strong>Dual-channel theorem at higher strand counts</strong> (<a href="../inventory/entries/demo_108.html">D108</a> seed) — <a href="../inventory/entries/demo_108.html">D108</a>'s     dual-channel theorem was established on 2-strand (quaternionic) DKC.     Does the same product-closure + v_2-connectivity discrimination hold     for multi-strand (matrix-valued) catalogs? The sign-hash activation at     n=6 (<a href="../inventory/entries/demo_103.html">D103</a>-<a href="../inventory/entries/demo_104.html">D104</a>) provides the natural test bed. If the dual-channel     structure generalizes, Raqiya-style diagnostics can be extended to     multi-strand catalogs. 1-2 demos.</p>
<p>---</p>
<h2>New Research Axes (from <a href="../inventory/entries/demo_64.html">D64</a>-<a href="../inventory/entries/demo_109.html">D109</a>)</h2>
<h3>1. Quaternionic DKC as a Research Axis</h3>
<p><a href="../inventory/entries/demo_66.html">D66</a>-<a href="../inventory/entries/demo_71.html">D71</a> established that the computation is intrinsically quaternionic and lives on S². This is a genuinely new dimension of the research, not an extension of the S¹ (complex) approach:</p>
<ul>
<li><strong>Bloch sphere = qubit state space = DKC computation space.</strong> The S²=CP¹ identification is not incidental. The rotation axis of a unit quaternion IS the Bloch sphere representation of a qubit. DKC with quaternionic weights is computing on the same geometric object that quantum information theory uses to represent single-qubit states.</li>
<li><strong>The 13-direction Voronoi as a quantum measurement basis.</strong> The 13 eigenvector directions of the binary octahedral group form a specific structured arrangement on S². Whether these 13 directions correspond to a known quantum measurement basis (e.g., a SIC-POVM or a mutually unbiased basis construction) is unexplored.</li>
<li><strong>24-cell as the natural computational polytope.</strong> The 24-cell is unique in 4D: the only regular self-dual polytope with no 3D analogue. Its 24 vertices arise naturally from SU(2) braid representations. The F4 symmetry group (576 elements) decomposes XOR6 solutions into exactly 6 orbits, which may reflect the partition structure of XOR arity (6 = 1+2+3).</li>
<li><strong>Hopf fibration as a computational factorization.</strong> The fiber phase carries nothing; the base carries everything. This means DKC naturally factors through the Hopf fibration: braid → SU(2) quaternion → S² direction → computation.</li>
</ul>
<h3>2. Spectral Theory of DKC</h3>
<p><a href="../inventory/entries/demo_71.html">D71</a> gave the first frequency-domain characterization of DKC. The 13=13 theorem is the cleanest theoretical result in the arc:</p>
<p><strong>Statement</strong>: The minimum spherical harmonic bandwidth for XOR6 DKC on the 13-direction S² eigenvector Voronoi is exactly l=6, because 2l+1 = 13 = the number of eigenvector directions. The phase transition at l=6 is sharp (0% recovery at l≤5, 100% at l=6) and all-or-nothing.</p>
<p><strong>Why this matters for the vision</strong>: <ul> <li>It explains, from first principles, WHY 14 cells suffice (compressed sensing + known support) and WHY the specific number 13 appears (degrees of freedom count at minimum bandwidth).</li> <li>It opens a spectral approach to DKC that is orthogonal to the algebraic (bracket value / cyclotomic integer) approach. Two independent frameworks for the same object strengthen the theoretical foundation.</li> <li>The spectral universality (all 36 XOR6 winners share the same spectral shape: l=6 dominant at ~80%) means the spectrum is a structural invariant of XOR6 solutions, not a per-solution artifact. This could enable spectral classification of what DKC can and cannot compute.</li> <li>The trivialization prediction works: for Z[zeta_16] with 3,457 directions, the DOF formula predicts l≥1728 minimum bandwidth, explaining the ~90% solution rate at Z[zeta_16] resolution. The spectral framework predicted this correctly from the direction count alone.</li> </ul>
<h3>3. Music as an Application and Outreach Direction</h3>
<p><a href="../inventory/entries/demo_70.html">D70</a> showed that the Z[zeta_8] algebra produces a natural musical system: 4 eigenvalue angles → 4 notes (C, Eb, E, F#), spanning maximum consonance (unison) to maximum dissonance (tritone). Braid words become melodies; the Yang-Baxter relation σ₁σ₂σ₁ = σ₂σ₁σ₂ produces identical melodies step by step (not just at the final note). Dissonance IS the antipodal map on the dodecahedron (tritone pairs = antipodal faces).</p>
<p><strong>Potential directions</strong>: <ul> <li>Knot invariants as a composition algorithm: the Garside element melody (Eb E F# E Eb C) is a complete rising-falling arch visiting all 4 knot notes. Different knot types produce structurally distinct melodies.</li> <li>Artistic collaborations: composers working with algebraic constraint rather than pure taste.</li> <li>Educational tools: music as an entry point to braid group theory, the Yang- Baxter equation, and knot theory. The Yang-Baxter identity becomes audible.</li> <li>Accessibility: DKC results that are otherwise abstract (bracket values, cyclotomic integers) become perceivable through pitch and rhythm.</li> </ul>
<h3>4. Matroid Theory Integration</h3>
<p><a href="../inventory/entries/demo_64.html">D64</a> showed the parity hierarchy {XOR2, XOR3, XOR4, XOR5} is a matroid minor chain with perfect downward deletion-contraction closure. The 44 good / 31 poison value split in the catalog vocabulary is structurally unexplored but possibly related to Reiner's cyclotomic matroids (mu_8, arXiv:math/0402206):</p>
<ul>
<li>Deletion: removing any weight from XOR_n gives XOR_{n-1} (100%).</li>
<li>Contraction: fixing any input to 1 gives XNOR_{n-1} (100%).</li>
<li>The 44 good values (extensible upward) vs. 31 poison values (orphan-only) may be the matroid's independent sets vs. circuits.</li>
<li>Poison values avoid octant 4 entirely — a geometric constraint on the circuit structure.</li>
</ul>
<p><strong>Why this matters</strong>: Matroid theory provides a combinatorial language for talking about which weight sets are "compatible" for extension. A matroid characterization of the DKC catalog would: <ul> <li>Unify the combinatorial (which sets work?) and algebraic (why do those values appear in the catalog?) sides of DKC.</li> <li>Provide a polynomial-time algorithm for testing extensibility (matroid membership tests are poly-time).</li> <li>Connect to the geometric (S² Voronoi) side via oriented matroid theory (oriented matroids = chirotopes = sign patterns of determinants, which are exactly what sector classification computes).</li> </ul>
<p>Status: UNEXPLORED. Reiner connection flagged. Needs a dedicated investigation.</p>
<h3>5. Activation Function Design Theory</h3>
<p>The progression across <a href="../inventory/entries/demo_50.html">D50</a>-<a href="../inventory/entries/demo_71.html">D71</a> suggests a principled theory of activation function design grounded in representation theory:</p>
<p><code></code>` Half-plane (binary threshold)   → Sector (k-sector MVN, Aizenberg)     → Generalized sector (non-standard binary labeling of k sectors, <a href="../inventory/entries/demo_65.html">D65</a>)       → Voronoi on S¹ (k=24, <a href="../inventory/entries/demo_65.html">D65</a>)         → Voronoi on S³ (24-cell, 25 cells, <a href="../inventory/entries/demo_66.html">D66</a>)           → Voronoi on S² (13-direction eigenvector, 14 cells, <a href="../inventory/entries/demo_67.html">D67</a>)             → Spectral (bandwidth l=6, 13=13 theorem, <a href="../inventory/entries/demo_71.html">D71</a>) <code></code>`</p>
<p>Each step reduces cell count while maintaining or improving XOR6 solvability. The endpoint — spectral characterization via spherical harmonics — provides an analytical framework that transcends the enumeration approach.</p>
<p><strong>The 13=13 theorem provides the DOF count</strong>: minimum bandwidth = minimum cell count needed for the computation, set by the number of data-intrinsic directions. This is a principled design criterion: <ul> <li>Don't choose activation cell count by convention (Aizenberg's odd/even) or by grid resolution (k sectors). Derive it from the data-intrinsic directions.</li> <li>The spectral bandwidth l tells you the minimum representation complexity of the labeling function. Functions below this bandwidth cannot be expressed; functions at or above it can.</li> <li>The representation-theoretic source of the directions (binary octahedral group, braid group SU(2) image) determines what bandwidth is needed.</li> </ul>
<p>This bridges pure math (representation theory, spectral analysis on S²) and practical ML architecture (how many neurons / activation cells do you need?).</p>
<h3>6. Depth-Based Catalog Engineering</h3>
<p><a href="../inventory/entries/demo_82.html">D82</a>'s central insight: algebraic coherence beats raw vocabulary. The depth law (max_xor ≈ depth + 6) means that what matters is not how many directions or angles the catalog covers, but how deeply the entries are constructed as products of generators.</p>
<p><strong>What this suggests for catalog design:</strong></p>
<p>The current approach is BFS enumeration — build the full group closure round by round, accept all resulting entries. This is expensive (exponential in depth) and produces a catalog with most entries at the deepest rounds (<a href="../inventory/entries/demo_82.html">D82</a> data: round 8 alone contributes 44% of all 4096 entries). But the shallow rounds are necessary because: 1. Depth-0 entries (generators + identity) appear in every winner at every XOR    level — they are the invariant skeleton. 2. The recursive structure (XOR8 winner = XOR6 triple + shadow) means shallower    entries propagate into deeper selections.</p>
<p><strong>The engineering question:</strong> Is there a catalog construction that generates entries with depth ≥ d directly, without the exponential intermediate cost? Characteristics of deep entries that might be exploitable: <ul> <li>They share common intermediate algebraic factors (products of 4 generators appear as sub-products of products of 8 generators).</li> <li>They occupy the "angle refinement" regime (depth 7-8 add new angles while directions are saturated) — angular resolution is the bottleneck, not directional coverage.</li> <li>The two-component winner structure (shallow core + deep extensions) is known: winners at XOR(n) have mean depth ~n/6. This is a design spec, not just an observation.</li> </ul>
<p><strong>Connection to the vision:</strong> For the hybrid LLM, compiled DKC neurons need to be generated efficiently at the inference/update time. If deep-entry generation can be done directly (without full BFS), the compilation cost drops from exponential to manageable. This is the bottleneck for making Gap 5 (dynamic recompilation) practical at ζ₁₂.</p>
<p>Status: CONCEPTUAL. <a href="../inventory/entries/demo_82.html">D82</a> identified the phenomenon and posed the direct- generation question. No implementation yet.</p>
<h3>7. Finite/Infinite Group Duality</h3>
<p><a href="../inventory/entries/demo_80.html">D80</a> established the two computational regimes. The vision question — getting the best of both — is more than an engineering optimization; it touches the deep structure of why DKC works at all.</p>
<p><strong>Why the finite/infinite distinction matters:</strong></p>
<p>In the finite case (ζ₈): the binary octahedral group closes at 24 elements. Every entry has an exact, named place in the ADE/McKay classification. The quantum dimension [2]_q = 0 at ζ₈ means the TL category is maximally non- semisimple at this point. The XOR capacity (ceiling at 8 inputs) can in principle be proven, not just measured. Kuperberg's #P-hardness doesn't apply because ζ₈ is a lattice root.</p>
<p>In the infinite case (ζ₁₂): the group never closes; it approaches a dense subgroup of SU(2). Every BFS round produces genuinely new algebraic structure. The XOR capacity is not bounded by group order — it is bounded only by the depth you can reach and the computational resources for catalog construction and search. But: the catalog is no longer fully characterizable. Entries at depth d are products of d generators, but the algebraic classification of the full infinite group is open (it's related to Kuperberg's #P-hard territory for irrational angles).</p>
<p><strong>Two research directions toward duality:</strong></p>
<p>1. <strong>Finite subgroups of infinite catalogs</strong>: at any depth d in a ζ₁₂ catalog,    the entries up to depth d form a finite set (though not closed under    multiplication). <a href="../inventory/entries/demo_82.html">D82</a>'s winner architecture (shallow core + deep extensions)    means the "shallow core" is a small finite structure that provides the    invariant skeleton, even when the overall catalog is infinite. Can this    shallow core be characterized as a finite algebraic object with ADE-style    guarantees?</p>
<p>2. <strong>Union catalogs</strong>: ζ₈ and ζ₁₂ are largely non-overlapping (12-15%    quaternion/direction overlap, <a href="../inventory/entries/demo_79.html">D79</a>). Their union could combine ζ₈'s fully    characterized structure with ζ₁₂'s depth-scalable capacity. The union    catalog hypothesis: using ζ₈ entries as the "shallow core" and ζ₁₂ entries    as the "deep extensions" in a winner construction might give higher capacity    than ζ₁₂ alone (because the ζ₈ core is algebraically specialized) while    maintaining ζ₁₂'s scalability.</p>
<p><strong>Connection to quantum information:</strong> The quantum dimension vanishing at ζ₈ is connected to the TL category being non-semisimple at this root — the same non-semisimplicity that gives DKC its computational power via the bracket-blind computation (<a href="../inventory/entries/demo_74.html">D74</a>). Infinite-group roots are non-semisimple in a different, less controlled way. The duality question may have a precise formulation in terms of monoidal category theory.</p>
<p>Status: CONCEPTUAL. Mathematical framework needed. Potentially a deep connection between TL non-semisimplicity, the ADE classification, and computational capacity.</p>
<h3>8. Resource Decomposition as Architectural Principle — NEW (<a href="../inventory/entries/demo_83.html">D83</a>)</h3>
<p><a href="../inventory/entries/demo_83.html">D83</a> established that DKC computational power is not a single monolithic quantity — it decomposes into three independent, additive axes:</p>
<p><code></code>` DKC capacity = lattice base (XOR6) + 2 × depth_rounds + 2 × framing_present <code></code>`</p>
<p>Each axis contributes +2 XOR levels independently: <ul> <li><strong>Lattice structure</strong> (the root of unity and its SU(2) image): provides the base capacity (XOR6 from the ζ₈ lattice alone).</li> <li><strong>Crossing depth</strong> (generator multiplications, <a href="../inventory/entries/demo_82.html">D82</a>): each unit of depth adds a fixed increment. The mechanism is angular refinement — deeper entries introduce finer angles within the same set of directions.</li> <li><strong>Writhe / framing</strong> (chirality accumulation, <a href="../inventory/entries/demo_83.html">D83</a>): the writhe-dependent phase factor <code>(-A³)^{-w}</code> contributes exactly +2 XOR levels. Jones normalization, which removes this factor, costs exactly 2 XOR levels at every root tested (ζ₈: bracket XOR8 → Jones XOR6; ζ₁₂: bracket XOR12 → Jones XOR10).</li> </ul>
<p>The three axes are genuinely independent: depth-writhe correlation r = 0.139 across 4096 ζ₁₂ entries. A deep entry can have low writhe (crossings cancel) or high writhe (crossings accumulate). Writhe alone can compute XOR6 (32 winners from writhe-only sums) but cannot reach XOR8 — full power requires the interaction of all three axes.</p>
<p><strong>Why this matters architecturally:</strong></p>
<p>For the hybrid LLM compilation pipeline, this means DKC weight selection can be optimized axis by axis: <ul> <li>Choose the root of unity (lattice structure) for the base capacity.</li> <li>Set the catalog depth for the crossing-depth contribution.</li> <li>Decide whether to use bracket (framing-aware, +2) or Jones (framing- normalized, -2) weights depending on the target function.</li> </ul>
<p>Each axis is a separately tunable hyperparameter. This connects directly to Gap 5 (dynamic recompilation): recompilation cost can be reduced by holding two axes fixed and varying only one. For instance, changing a compiled neuron's capacity by +2 XOR levels can be achieved by deepening the catalog one round (holding root and writhe strategy constant), rather than rebuilding from scratch.</p>
<p><strong>Framing as computation — inverting a 35-year-old assumption:</strong></p>
<p>Witten (1989) identified the writhe-dependent phase as a "framing anomaly" — the first term removed when passing from the bracket to the Jones polynomial to make the invariant topologically well-defined. TQFT's maximally degenerate point (δ=0, where the quantum dimension vanishes at ζ₈) discards this term first. <a href="../inventory/entries/demo_83.html">Demo 83</a> demonstrates that the "anomaly" is not bookkeeping noise but genuine computational content: exactly the component worth +2 XOR levels. This inverts 35 years of TQFT convention: what TQFT normalized away as an artifact, DKC uses as a resource. For the DKC research program, this means we should be suspicious of any normalization that discards information — the discarded terms may be computationally valuable.</p>
<p>Status: DEMONSTRATED (ζ₈ and ζ₁₂). Predicted universal across all roots but needs verification at ζ₁₆ and ζ₂₄.</p>
<h3>9. Null States and the Reservoir Computing Connection — NEW (<a href="../inventory/entries/demo_84.html">D84</a>)</h3>
<p><a href="../inventory/entries/demo_84.html">D84</a> established the first concrete bridge between DKC and Reservoir Computing (RC). The connection runs through null states — bracket-null entries where Re(q) = 0 (Kauffman trace vanishes).</p>
<p><strong>The null-state thesis:</strong></p>
<p>In the ζ₈ catalog (24 entries, binary octahedral group), 9 entries (37.5%) are bracket-null. These are not dead weight. They maintain 6 unique S² directions (cube-edge-midpoint axes) that are unavailable to non-null entries. Removing nulls collapses XOR capacity from XOR8 to XOR6 — worse than removing a random equal-size subset (random-15 mean = XOR7.8). Nulls are disproportionately important because they provide directional coverage of S² regions that the non-null entries do not reach.</p>
<p>This directly maps onto the RC separation property: a reservoir needs its high-dimensional manifold to remain open in all critical directions for linear readout to succeed. Null reservoir states (zero output under readout) are conventionally assumed to be wasted capacity. <a href="../inventory/entries/demo_84.html">D84</a> proves this assumption wrong for quaternionic DKC: the null states hold the manifold open in exactly the directions needed for higher-order parity separation.</p>
<p><strong>Concrete RC↔DKC mapping:</strong></p>
<table><thead><tr><th>RC Concept</th><th>DKC Analog</th></tr></thead><tbody><tr><td>Reservoir state</td><td>Quaternionic weight (catalog entry)</td></tr><tr><td>Null reservoir state</td><td>Bracket-null entry (Re(q)=0)</td></tr><tr><td>Separation property</td><td>S² directional coverage enabling XOR</td></tr><tr><td>High-dimensional manifold</td><td>13-direction Voronoi on S²</td></tr><tr><td>Linear readout</td><td>Sector-threshold activation</td></tr><tr><td>Null state maintains manifold</td><td>Null directions hold Voronoi open</td></tr></tbody></table>
<p>The null fraction dilutes as the group grows (ζ₄: 75%, ζ₈: 37.5%, ζ₁₂: 3%), consistent with nulls being a finite-group boundary effect. But at ζ₈ — the most algebraically structured point (ADE type E₇, quantum dimension zero, maximally non-semisimple TL category) — they are a major structural fraction, and their role is unmistakable.</p>
<p><strong>Implication for the hybrid LLM:</strong> When designing compiled DKC neurons, the weight set should not be pruned to only include "active" (non-null) entries. Null weights serve a structural role — they maintain the geometric separation needed for the neuron to compute higher-order functions. This is a concrete design constraint for compiled weight matrices.</p>
<p>Status: DEMONSTRATED at ζ₈. Role of nulls at ζ₁₂ (where they are 3% of the catalog but contribute 29 unique directions) is an open question.</p>
<h3>10. The LCFT Bridge — NEW (<a href="../inventory/entries/demo_84.html">D84</a>)</h3>
<p><a href="../inventory/entries/demo_84.html">D84</a> opened a bridge to Logarithmic Conformal Field Theory (LCFT) that was not in the vision before. The connection:</p>
<p>In LCFT (Gurarie 1993, Gaberdiel-Kausch 1996), null states |N⟩ satisfy ⟨N|N⟩ = 0 but are not zero vectors. They are paired with logarithmic partners |L⟩ through Jordan-cell (non-diagonalizable) action of the Virasoro zero-mode L₀:</p>
<p><code></code>` L₀ |N⟩ = h |N⟩ L₀ |L⟩ = h |L⟩ + |N⟩ <code></code>`</p>
<p>The two-point function of |N⟩ vanishes, but the mixed correlator ⟨N|L⟩ is nonzero. Computational content lives in the Jordan-cell coupling.</p>
<p>In quaternionic DKC: bracket-null entries (Re(q) = 0, trace vanishes) are the |N⟩ states. Their "logarithmic partners" are non-null entries sharing the same S² direction (the 3 coordinate-axis directions where both null and non-null entries co-exist). The 6 null-only directions (cube-edge-midpoints, no non-null partner) have no logarithmic partner in the catalog — consistent with the observation that removing these directions destroys capacity rather than merely reducing it.</p>
<p><strong>The dense polymer connection:</strong> The Temperley-Lieb algebra at δ = 0 (the loop value when [2]_q vanishes at ζ₈) is the algebraic description of dense polymers — the c = -2 LCFT. The dense polymer model at β = 0 is precisely the LCFT analog of the ζ₈ bracket. This means:</p>
<ul>
<li>ζ₈ DKC lives at the dense polymer / c = -2 LCFT point.</li>
<li>The Jordan-cell structure of the c = -2 theory (indecomposable but reducible representations of the Virasoro algebra) directly describes the null / non-null pairing in the DKC catalog.</li>
<li>The indecomposability parameter b (Gurarie's "b-number") should be calculable from the ζ₈ catalog structure. This is a concrete prediction.</li>
</ul>
<p><strong>Why this matters for the vision:</strong></p>
<p>DKC now sits at the intersection of three previously disconnected fields:</p>
<p><code></code>`         LCFT (c = -2, dense polymers)               ↗     DKC ← TQC (Temperley-Lieb, Jones, braids)               ↘         RC (reservoir computing, separation property) <code></code>`</p>
<p>Nobody has mapped this three-way intersection. The existing literature touches pairs: LCFT ↔ TL (Pearce, Read, Saleur), TL ↔ Jones (Kauffman, Kuperberg), RC ↔ neural nets (Jaeger, Maass). But the triangle — LCFT null states as RC separation maintainers computed via TL bracket at δ = 0 — is novel. This is potentially the deepest structural insight to date: the non-semisimple part of the TL algebra is simultaneously what makes LCFT "logarithmic" (Jordan cells instead of diagonal), what makes DKC compute (null directions holding the manifold open), and what makes the reservoir work (separation property through geometrically essential null states).</p>
<p>Status: INTERPRETATION, PARTIALLY CONFIRMED. Jordan-cell pairing is consistent with all data. The indecomposability parameter b = -5/8 has been computed from first principles at TL_4 (<a href="../inventory/entries/demo_85.html">D85</a>), confirming the LCFT correspondence quantitatively. <a href="../inventory/entries/demo_86.html">D86</a> established that b is a collective property of the full algebra (single P_{0,0} universally diverges). Dense polymer fusion rules remain a concrete next verification.</p>
<h3>11. Non-Semisimplicity as THE Resource — NEW (<a href="../inventory/entries/demo_50.html">D50</a>→<a href="../inventory/entries/demo_82.html">D82</a>→<a href="../inventory/entries/demo_84.html">D84</a> Arc)</h3>
<p>The thread from <a href="../inventory/entries/demo_50.html">D50</a> through <a href="../inventory/entries/demo_82.html">D82</a> to <a href="../inventory/entries/demo_84.html">D84</a> converges on a single deep claim: the non-semisimple part of the Temperley-Lieb algebra is not an obstacle or a degenerate edge case — it IS what makes DKC work.</p>
<p><strong>The convergence:</strong></p>
<ul>
<li><strong><a href="../inventory/entries/demo_50.html">D50</a></strong>: The parity wall was in the activation function, not the lattice. Increasing sectors from k=2 to k=6 unlocked all 13 NPN classes. The wall that looked algebraic was geometric — the activation was too coarse to resolve the lattice structure.</li>
<li><strong><a href="../inventory/entries/demo_65.html">D65</a>-<a href="../inventory/entries/demo_67.html">D67</a></strong>: The activation progression (sector → generalized sector → Voronoi on S¹ → Voronoi on S³ → Voronoi on S²) culminated in the 13- direction eigenvector Voronoi. The 13 directions are exactly the eigenvector axes of the binary octahedral group — a structure that exists only because the ζ₈ representation is non-semisimple (in a semisimple representation, eigenvectors would not form discrete clusters on S²).</li>
<li><strong><a href="../inventory/entries/demo_82.html">D82</a></strong>: Crossing depth governs XOR capacity via the depth law max_xor ≈ depth + 6. The depth mechanism is algebraic coherence — deep entries carry shared intermediate products from generator multiplication chains. These chains exist because the algebra is infinite-dimensional (at ζ₁₂) or has non-trivial Jordan structure (at ζ₈). In a semisimple algebra, all entries would be direct sums of irreducibles with no interesting depth structure.</li>
<li><strong><a href="../inventory/entries/demo_83.html">D83</a></strong>: Framing (writhe) contributes +2 XOR levels. The writhe-dependent phase factor is precisely the term that TQFT removes at δ = 0 (the non-semisimple point). The computational resource IS the non-semisimple contribution.</li>
<li><strong><a href="../inventory/entries/demo_84.html">D84</a></strong>: Null states — the most extreme manifestation of non-semisimplicity (zero trace, indecomposable but reducible representations) — are indispensable for XOR8 capacity. Removing them drops capacity below the random baseline. The Jordan-cell structure (non-diagonalizable L₀ action) is the algebraic mechanism: the null state anchors the logarithmic partner that carries the computation.</li>
</ul>
<p><strong>The claim:</strong> At the ζ₈ point (quantum dimension [2]_q = 0, δ = 0, dense polymer / c = -2 LCFT), the TL category is maximally non-semisimple. Every feature of DKC that contributes computational power — the discrete direction spectrum, the depth structure, the writhe contribution, the null-state manifold maintenance — is a consequence of this non-semisimplicity. A semisimple TL category (at generic q, δ ≠ 0) would have: <ul> <li>A continuum of directions (no discrete Voronoi)</li> <li>Trivial depth structure (all irreducibles immediately accessible)</li> <li>No null states (all representations fully reducible)</li> <li>No framing anomaly (Jones and bracket would agree)</li> </ul>
<p><strong>Implication for the vision:</strong> The maximally non-semisimple point is not a degenerate corner to be avoided — it is the sweet spot for compiled computation. The entire DKC research program is, in retrospect, an exploration of what computation looks like when you sit at the most singular point of the quantum group parameter space. This is the opposite of the standard quantum computing approach (which avoids non-semisimple points because they make the Jones polynomial evaluation trivial in the Kuperberg sense). DKC thrives precisely where quantum computing gives up.</p>
<p>Status: INTERPRETIVE SYNTHESIS. Each individual result is demonstrated; the overarching claim about non-semisimplicity is a unifying interpretation.</p>
<h3>12. Encoding as a Design Dimension — NEW (<a href="../inventory/entries/demo_92.html">D92</a>)</h3>
<p><a href="../inventory/entries/demo_92.html">D92</a> proves that the encoding — how input bits are mapped to quaternion multipliers — determines which Boolean functions are computable at all. This is not a tuning knob; it is a structural selector. The +/-q encoding creates 3^k equivalence classes (per-weight effective states {-q, 0, +q}), and XOR/XNOR are the ONLY standard Boolean functions constant on all classes.</p>
<p><strong>Why this is a new research axis, not just a gap:</strong></p>
<p>The encoding question is not "which encoding is best?" but "what is the space of possible encodings, and what does each one select for?" This is a design dimension in the sense that different points in encoding space produce qualitatively different computational capabilities:</p>
<ul>
<li><strong>+/-q paired encoding</strong>: selects for parity (the hardest function outside AC^0). Creates equivalence classes via per-weight pair cancellation. The depth law holds with slope ~1.</li>
<li><strong>1wpi encoding</strong>: selects for all 13 NPN classes (<a href="../inventory/entries/demo_48.html">D48</a>/<a href="../inventory/entries/demo_50.html">D50</a>). One weight per input bit, no pairing. Depth-law behavior unknown.</li>
<li><strong>Hybrid encodings</strong>: some weights paired, some independent. Potentially access intermediate function sets. Completely unexplored.</li>
</ul>
<p>The encoding design dimension is orthogonal to the activation design dimension (Research Axis 5). Activation determines resolution (how many solutions); encoding determines reachability (which functions). Together they form a 2D design space where each (encoding, activation) pair produces a specific computational profile.</p>
<p><strong>Connection to the vision:</strong> For the hybrid LLM, different compiled neurons may need different encodings depending on the logical function they implement. A syllogism-implementing neuron needs AND/OR/implication (1wpi encoding); a parity-check neuron needs XOR (+/-q encoding). The encoding is part of the compilation specification, not a global architectural choice.</p>
<p>The parity-lock theorem (<a href="../inventory/entries/demo_92.html">D92</a>) is also the 4th formal proof in the program (after radical dimension, next-level radical, and Markov RT truncation). It is the first proof that constrains the design space rather than characterizing capacity — a qualitative shift in the theoretical program's maturity.</p>
<p>Status: PARITY-LOCK PROVED. Encoding space exploration NOT STARTED. The 1wpi depth law is the immediate next question.</p>
<h3>13. Relational Computation as a Design Principle — NEW (<a href="../inventory/entries/demo_89.html">D89</a>-<a href="../inventory/entries/demo_91.html">D91</a>)</h3>
<p><a href="../inventory/entries/demo_89.html">D89</a>-<a href="../inventory/entries/demo_91.html">D91</a> establish that the depth law mechanism is relational: what matters is how catalog entries RELATE to each other (axis cancellation, cross-depth algebraic constraints), not where they individually sit on S². The spectral inversion result (<a href="../inventory/entries/demo_90.html">D90</a>) is the cleanest evidence: the S² point cloud bandwidth DECREASES with depth while computation INCREASES — positional information degrades monotonically while relational information grows.</p>
<p><strong>The relational computation thesis:</strong></p>
<p><code></code>` Positional properties:    entry direction, entry angle, spherical design quality                           → DECREASE with depth (spectral inversion)                           → WRONG optimization target</p>
<p>Relational properties:    axis cancellation (anti-aligned pairs, min_dot ≈ -0.75),                           cross-depth algebraic constraint (73 distinct angles                           from 50K gen×deep pairs), BFS ancestry structure                           → INCREASE with depth                           → CORRECT optimization target <code></code>`</p>
<p>This is not just a correction of one hypothesis — it inverts the entire intuition about what "good" catalog entries look like. Individual entry quality (positional metrics like angular spacing, direction coverage, spherical design residual) is fundamentally misleading. Optimizing for positional quality would move the catalog AWAY from computation (<a href="../inventory/entries/demo_72.html">D72</a>: 89% XOR loss under Voronoi optimization).</p>
<p><strong>Implications for catalog engineering:</strong></p>
<p>The correct catalog optimization problem is not: "place N entries to maximize coverage of S²." It is: "select N entries to maximize pairwise axis cancellation quality and cross-depth algebraic constraint density." This is a combinatorial optimization over relationships, not a geometric optimization over positions.</p>
<p>Specific relational metrics identified by <a href="../inventory/entries/demo_89.html">D89</a>-<a href="../inventory/entries/demo_91.html">D91</a>: <ul> <li><strong>Axis cancellation quality</strong>: XOR winners have mean(min_dot) = -0.75 vs -0.65 for non-winners. Deeper entries produce more anti-aligned axis pairs.</li> <li><strong>Cross-depth vocabulary constraint</strong>: Gen × deep-entry sums produce only 73 distinct angles from 50K pairs. BFS ancestry creates algebraic relationships that restrict pairwise sum-angle vocabularies.</li> <li><strong>Balanced exponentials</strong>: BFS vocabulary grows ~2x/round, parity demand grows 4x/weight. The ratio determines the depth law slope (~1).</li> </ul>
<p><strong>Connection to the vision:</strong> For the hybrid LLM compilation pipeline, this means weight selection algorithms should optimize relational properties of the weight set, not individual weight quality. A compiled neuron's power depends on how its weights interact, not on where they individually sit in the algebraic catalog.</p>
<p>Status: MECHANISM DEMONSTRATED (<a href="../inventory/entries/demo_89.html">D89</a>-<a href="../inventory/entries/demo_91.html">D91</a>). Relational optimization algorithms NOT STARTED. The balanced exponentials slope derivation is the next clean formal proof candidate.</p>
<h3>14. Regime-Dependent Design Principles — NEW (<a href="../inventory/entries/demo_87.html">D87</a>-<a href="../inventory/entries/demo_88.html">D88</a>)</h3>
<p><a href="../inventory/entries/demo_87.html">D87</a>-<a href="../inventory/entries/demo_88.html">D88</a> establish that design principles for DKC neurons are not universal — they depend qualitatively on whether the underlying group is finite or infinite.</p>
<p><strong>The two regimes:</strong></p>
<table><thead><tr><th>Property</th><th>Finite (ζ₈, 24 entries)</th><th>Infinite (ζ₁₂, 4096 entries)</th></tr></thead><tbody><tr><td>Null fraction</td><td>37.5%</td><td>3.0%</td></tr><tr><td>Null indispensability</td><td>CRITICAL (XOR8→XOR4 without nulls)</td><td>DISPENSABLE (XOR12 preserved)</td></tr><tr><td>Direction density</td><td>13 dirs (sparse)</td><td>2043 dirs (dense)</td></tr><tr><td>Per-dir residual</td><td>0.171</td><td>0.021 (8× lower)</td></tr><tr><td>Dominant pathway</td><td>Shadow pairing (100%)</td><td>Direction diversity (80-94%)</td></tr><tr><td>Perturbation sensitivity</td><td>Non-null anchors fragile, null scaffolding flexible</td><td>Dense dirs absorb perturbation</td></tr></tbody></table>
<p>The transition mechanism is direction density: when non-null directions are dense enough on S², losing null-only directions cannot constrain combinatorial search. At ζ₈ (13 directions, 6 null-only), every direction matters. At ζ₁₂ (2043 directions, 67 null-only), the 1976 non-null directions provide sufficient combinatorial diversity.</p>
<p><strong>The two-role direction architecture (<a href="../inventory/entries/demo_88.html">D88</a>):</strong></p>
<p>At ζ₈, the 13 cuboctahedral directions serve two distinct computational roles: <ul> <li>4 non-null body diagonals = rigid computational anchors (perturbation- sensitive, load-bearing for XOR). Moving them 10° causes 8% XOR loss.</li> <li>6 null-only edge midpoints = flexible topological scaffolding (perturbation- tolerant, movable). Moving them 10° causes -2.4% loss (a GAIN).</li> </ul>
<p>Constrained optimization (nulls free, non-nulls clamped to 2°) captures 92% of design improvement with only 2.8% XOR loss. The k-ladder activation provides 14× better perturbation resilience than Voronoi-only (6.4% vs 89% loss under the same design-improving gradient).</p>
<p><strong>Implications for the vision:</strong></p>
<p>A practical hybrid LLM using compiled DKC neurons would need regime-aware compilation strategies: <ul> <li><strong>Finite-group neurons</strong> (ζ₈): preserve null entries, protect non-null anchor positions, use k-ladder activation for robustness.</li> <li><strong>Infinite-group neurons</strong> (ζ₁₂): safe to prune null entries, direction diversity is the dominant capacity driver, perturbation resilience is inherent.</li> </ul>
<p>The exact transition threshold (at what catalog size / direction density / null fraction does the regime change?) is unknown. Locating it would give a concrete design criterion: below the threshold, use finite-group design rules; above, use infinite-group rules.</p>
<p>Status: TWO REGIMES DEMONSTRATED (<a href="../inventory/entries/demo_87.html">D87</a>-<a href="../inventory/entries/demo_88.html">D88</a>). Transition threshold UNKNOWN. The regime question may have a sharp answer in terms of direction density or null fraction.</p>
<h3>15. Formal Proofs as a Maturing Theoretical Framework — NEW (<a href="../inventory/entries/demo_92.html">D92</a>)</h3>
<p>The parity-lock theorem (<a href="../inventory/entries/demo_92.html">D92</a>) is the 4th formal proof in the program:</p>
<table><thead><tr><th>#</th><th>Proof</th><th>Demo</th><th>What it establishes</th></tr></thead><tbody><tr><td>P01</td><td>Radical dimension formula</td><td><a href="../inventory/entries/demo_39.html">D39</a></td><td>dim(rad) = f(l) — algebraic structure</td></tr><tr><td>P02</td><td>Next-level radical structure</td><td><a href="../inventory/entries/demo_39.html">D39</a></td><td>radical propagation — algebraic depth</td></tr><tr><td>P03</td><td>Markov RT truncation</td><td><a href="../inventory/entries/demo_51.html">D51</a></td><td>trace form properties — algebraic tools</td></tr><tr><td>P04</td><td>Parity-lock theorem</td><td><a href="../inventory/entries/demo_92.html">D92</a></td><td>+/-q encoding computes only XOR/XNOR — design constraint</td></tr></tbody></table>
<p>The qualitative shift: P01-P03 characterize the algebraic substrate (what the algebra looks like). P04 constrains the design space (what the algebra can and cannot do under a specific encoding). This is the transition from "what is DKC?" to "what are DKC's structural limits?" — from exploration to theory.</p>
<p><strong>The proof pipeline is accelerating:</strong></p>
<p><a href="../inventory/entries/demo_89.html">D89</a>-<a href="../inventory/entries/demo_91.html">D91</a> identified two more proof-ready results: <ul> <li><strong>Balanced exponentials</strong>: the linear depth law slope as a theorem (BFS branching factor ~2×/round vs parity demand 4×/weight → slope ~1). This would be P05.</li> <li><strong>Spectral inversion</strong>: S² bandwidth decreases with depth while computation increases. A formal statement and proof would be P06.</li> </ul>
<p><a href="../inventory/entries/demo_87.html">D87</a> identified a potential threshold theorem: <ul> <li><strong>Regime transition</strong>: a sharp threshold for null dispensability as a function of direction density. This would be P07 if it admits a clean statement.</li> </ul>
<p><strong>Why this matters for the vision:</strong></p>
<p>The hybrid LLM vision requires credibility in academic and engineering contexts. Moving from "computationally verified" to "formally proved" is the difference between an empirical observation and a structural guarantee. Four proofs (and a pipeline of candidates) means the theoretical framework is approaching the maturity needed for external engagement — publications, collaborations, and engineering specifications grounded in proven properties rather than measured heuristics.</p>
<p>Status: 4 FORMAL PROOFS COMPLETE. 3 candidates in pipeline (balanced exponentials, spectral inversion, regime transition threshold).</p>
<h3>16. DKC as Discrete Algebraic Reservoir Computer — NEW (<a href="../inventory/entries/demo_93.html">D93</a>-<a href="../inventory/entries/demo_94.html">D94</a>) — FIVE-PILLAR SYNTHESIS COMPLETE</h3>
<p><a href="../inventory/entries/demo_93.html">D93</a>-<a href="../inventory/entries/demo_94.html">D94</a> complete the five-pillar synthesis connecting DKC to five independent theoretical traditions. This is not a new analogy — it is a precise mathematical mapping with testable quantitative predictions.</p>
<p><strong>The five pillars (all connected through <a href="../inventory/entries/demo_94.html">D94</a>):</strong></p>
<p><code></code>` Pillar 1: TL algebra as computation (Abramsky 2009)     DKC catalog = TL algebra representation     → connected via bracket values as group elements</p>
<p>Pillar 2: Barrington's theorem (1989) — branching programs over groups     Non-solvable groups strictly more powerful for NC^1     → CONFIRMED by <a href="../inventory/entries/demo_94.html">D94</a>: 2I (non-solvable) &gt; z8 (solvable) at matched size</p>
<p>Pillar 3: Nazer-Gastpar compute-and-forward (2011)     DKC's signed sum = linear readout of algebraic reservoir     → the additive readout mechanism</p>
<p>Pillar 4: MVN neurons (Aizenberg 2008) — k-sector activation     DKC activation = nonlinear reservoir output function     → <a href="../inventory/entries/demo_93.html">D93</a>: phase_cell vs combined_cell determines function reachability</p>
<p>Pillar 5: Reservoir computing (Maass 2002, Gonon-Ortega 2020)     Fixed catalog = reservoir, Cayley graph = connectivity,     signed sum = linear readout, activation = nonlinear output,     BFS depth = memory depth     → <a href="../inventory/entries/demo_94.html">D94</a> proposes precise mapping, <a href="../inventory/entries/demo_95.html">D95</a> RKHS kernel test validates it <code></code>`</p>
<p><strong>The precise DKC ↔ Reservoir mapping (<a href="../inventory/entries/demo_94.html">D94</a>):</strong></p>
<table><thead><tr><th>Reservoir Computing Concept</th><th>DKC Analog</th></tr></thead><tbody><tr><td>Reservoir (fixed recurrent network)</td><td>Quaternion catalog (BFS closure of generators)</td></tr><tr><td>Reservoir state at time t</td><td>Signed sum of selected catalog entries</td></tr><tr><td>Input-to-reservoir coupling</td><td>1wpi encoding: input bits select weights</td></tr><tr><td>Reservoir topology (connectivity)</td><td>Cayley graph of the SU(2) subgroup</td></tr><tr><td>Linear readout</td><td>Quaternion inner product (Nazer-Gastpar)</td></tr><tr><td>Nonlinear output function</td><td>Activation (phase_cell / combined_cell / Voronoi)</td></tr><tr><td>Memory depth</td><td>BFS depth (crossing depth of catalog entries)</td></tr><tr><td>Separation property</td><td>XOR capacity (ability to separate function classes)</td></tr><tr><td>Echo state property</td><td>Group closure (catalog is a fixed point of BFS)</td></tr><tr><td>Kernel K(m,m')</td><td>Quaternion inner product of signed sums</td></tr></tbody></table>
<p><strong>Testable prediction (<a href="../inventory/entries/demo_95.html">D95</a>):</strong> rank(K_2I)/rank(K_z8) &gt; 120/24 = 5. If non-solvability contributes above raw catalog size, the kernel rank ratio exceeds the catalog size ratio. One number validates the entire framework.</p>
<p><strong>Why this is a milestone:</strong></p>
<p>Before <a href="../inventory/entries/demo_94.html">D94</a>, these five traditions were connected only pairwise at best: <ul> <li>TL ↔ Jones polynomial (Kauffman, Kuperberg)</li> <li>Reservoir ↔ neural nets (Jaeger, Maass)</li> <li>Barrington ↔ circuit complexity (textbook)</li> <li>MVN ↔ Boolean functions (Aizenberg)</li> <li>Nazer-Gastpar ↔ lattice codes (coding theory)</li> </ul>
<p><a href="../inventory/entries/demo_94.html">D94</a> connects ALL FIVE through a single computational object (the DKC neuron with 1wpi encoding under phase_cell on the 2I catalog). This is the first time these traditions have been unified. The circuit complexity hierarchy from <a href="../inventory/entries/demo_93.html">D93</a> (AND/XOR ratio = Hastad + LMN + Furst-Saxe-Sipser made concrete) provides the computational content; the 2I group structure from <a href="../inventory/entries/demo_94.html">D94</a> (Barrington's theorem validated) provides the algebraic content; the reservoir framing provides the architectural content.</p>
<p><strong>Connection to the vision:</strong> The "discrete algebraic reservoir computer" is a precise name for what DKC IS, not just what it resembles. For the hybrid LLM, each compiled neuron is literally a discrete algebraic reservoir computer with a fixed catalog, linear readout, and nonlinear activation. The reservoir framework provides design principles (echo state property → catalog construction, separation property → capacity prediction, kernel methods → weight selection) that translate directly to the compilation pipeline.</p>
<p>Status: FIVE-PILLAR SYNTHESIS COMPLETE (<a href="../inventory/entries/demo_94.html">D94</a>). RKHS kernel test (<a href="../inventory/entries/demo_95.html">D95</a>) is the quantitative validation. If confirmed, this is the deepest structural result in the program — not a new observation but a new framework connecting all previous observations.</p>
<h3>17. Multi-Strand DKC and the sl_d Functor Thesis — NEW (<a href="../inventory/entries/demo_95.html">D95</a>-<a href="../inventory/entries/demo_101.html">D101</a>)</h3>
<p><a href="../inventory/entries/demo_95.html">D95</a>-<a href="../inventory/entries/demo_101.html">D101</a> open a major new research axis: extending DKC from 2-strand (quaternionic) representations to n-strand Temperley-Lieb representations over Z[zeta_8]. This is not a straightforward generalization — it reveals qualitatively new phenomena at every strand count tested.</p>
<p><strong>The sl_d functor thesis (<a href="../inventory/entries/demo_100.html">D100</a>-<a href="../inventory/entries/demo_101.html">D101</a>):</strong></p>
<p>The BFS growth rate on n-strand TL standard modules tracks n-1 (the number of TL generators): <ul> <li>n=3 (W_{3,1}): growth ~2x/round → 2 generators</li> <li>n=4 (W_{4,2}): growth ~3.1x/round → 3 generators</li> <li>n=5 (W_{5,3}): growth ~4x/round → 4 generators</li> </ul>
<p>This is the sl_d functor in action: the standard module W_{n,k} carries an action of sl_{n-1} through the TL generators e_1, ..., e_{n-2}, and the BFS growth rate measures the effective branching factor of this action. CONFIRMED at n=3,4,5. The n=6 test (W_{6,4}, predicted ~5x growth) is the decisive next validation.</p>
<p><strong>Key findings by strand count:</strong></p>
<p><strong>3-strand (<a href="../inventory/entries/demo_98.html">D98</a>-<a href="../inventory/entries/demo_99.html">D99</a>):</strong> <ul> <li>Infinite group (2048 BFS entries at depth 7, still growing)</li> <li>Readout bottleneck: trace readout = ZERO XOR6 (catastrophically lossy); column-vector readout = 100% retention. The trace contracts 3x3 matrices to scalars, destroying the multi-strand information</li> <li>Ext^1 catalytic preparation (<a href="../inventory/entries/demo_99.html">D99</a> — LANDMARK): non-semisimple extensions (Jordan blocks in the 6D W_{3,1} module) enable an algebraic regime producing XOR6=500K solutions, XOR10-14=60 solutions. WITHOUT the Ext^1 structure, zero solutions above XOR6</li> <li>Two regimes: combinatorial (XOR6-8, proportional to catalog size) vs algebraic (XOR10-14, from non-semisimple extension structure)</li> <li>Star-graph topology: all entries connected through 2-3 super-hubs</li> <li>XOR16=0 ceiling (hard wall at current parameters)</li> </ul>
<p><strong>4-strand (<a href="../inventory/entries/demo_100.html">D100</a>):</strong> <ul> <li>W_{4,2}: 3x3 matrices over Z[zeta_8], ~3.1x BFS growth</li> <li>Radical dimension 9 (non-semisimple, significant radical content)</li> <li>6 super-hubs, constant radical content across hubs</li> <li>Casimir-XOR correlation: higher Casimir → higher XOR (1.36x-1.86x)</li> <li>All hub commutators are traceless with zero radical content</li> </ul>
<p><strong>5-strand (<a href="../inventory/entries/demo_101.html">D101</a>):</strong> <ul> <li>W_{5,3}: 5x5 matrices over Z[zeta_8], ~4x BFS growth</li> <li>SIMPLE module (radical dimension = 0, no non-semisimple extensions)</li> <li>Only 3 super-hubs (hub count FALSIFIED — predicted 12, observed 3)</li> <li>Casimir INVERSION: high-XOR winners have LOWER Casimir (opposite of <a href="../inventory/entries/demo_100.html">D100</a>)</li> <li>XOR14=0 ceiling (simple module ceiling, likely structural)</li> </ul>
<p><strong>The Ext^1 finding — non-semisimple extensions are computationally load-bearing:</strong></p>
<p><a href="../inventory/entries/demo_99.html">D99</a>'s most significant result is that the Ext^1 structure (non-trivial extensions between simple modules creating Jordan blocks) is what enables the algebraic computation regime. This directly extends Research Axis 11 (non-semisimplicity as THE resource): the resource is not just non-semisimplicity in the TL algebra itself, but non-semisimplicity in the specific MODULE being used as the computational substrate.</p>
<p>The comparison between <a href="../inventory/entries/demo_100.html">D100</a> (W_{4,2}, non-semisimple, radical dim=9) and <a href="../inventory/entries/demo_101.html">D101</a> (W_{5,3}, simple, radical dim=0) is the cleanest evidence: the non-semisimple module produces richer computation (higher XOR capacity relative to module dimension) despite operating on smaller matrices. The simple module has more algebraic room (5x5 vs 3x3) but less computational leverage because it lacks the Jordan-block structure that enables the algebraic regime.</p>
<p><strong>Readout as the multi-strand frontier:</strong></p>
<p>The trace readout catastrophe at 3-strand (<a href="../inventory/entries/demo_98.html">D98</a>) identifies readout design as the critical problem for multi-strand DKC. The column-vector readout preserves information but requires choosing WHICH column — a new design dimension that does not exist in 2-strand (where the quaternion IS the readout). For multi- strand, the readout function maps n×n matrices to scalars (or vectors), and the choice of readout determines whether the multi-strand information is preserved or destroyed.</p>
<p><strong>Connection to the vision:</strong></p>
<p>Multi-strand DKC dramatically expands the DKC design space along three new dimensions: 1. <strong>Strand count</strong> (n): determines BFS growth rate, module dimension, and    the sl_d algebraic structure 2. <strong>Module choice</strong> (simple vs non-semisimple): determines whether the    algebraic computation regime is accessible 3. <strong>Readout function</strong> (trace vs column vs other): determines whether    multi-strand information survives to the activation layer</p>
<p>For the hybrid LLM compilation pipeline, multi-strand opens the possibility of higher-dimensional compiled neurons with richer computational capacity, at the cost of more complex readout design. The sl_d functor thesis provides a systematic program: test each strand count, each module type, each readout — with predictions from the functor (growth rate = n-1) guiding which configurations to prioritize.</p>
<p>Status: ACTIVE RESEARCH FRONTIER. sl_d growth confirmed at n=3,4,5,6. Hub count scaling FALSIFIED. Ext^1 thesis established but needs formalization. Simple vs non-semisimple comparison is the key qualitative finding. Barrington-Radical Principle (<a href="../inventory/entries/demo_102.html">D102</a>) sharpens the claim: the radical itself is inert (abelian writhe character), but the extension structure of non-semisimple modules remains computationally useful.</p>
<h3>18. The Barrington Bridge: DKC Meets Circuit Complexity — NEW (<a href="../inventory/entries/demo_102.html">D102</a>)</h3>
<p><a href="../inventory/entries/demo_102.html">D102</a> produces the first connection between DKC and classical computational complexity theory. The Barrington-Radical Principle names the theorem: the radical of a non-semisimple TL module at delta=0 carries the writhe homomorphism B_n → Z/8Z (via A = -zeta_8), which is an abelian character. By Barrington's theorem (1989), abelian groups cannot compute parity. The radical direction is therefore provably useless for XOR computation — not just empirically poor, but theoretically guaranteed inert.</p>
<p><strong>Why this is a bridge, not just a theorem:</strong></p>
<p>Barrington's theorem is a foundational result in circuit complexity: width-5 branching programs over non-solvable groups (like S_5) compute exactly NC^1. DKC's catalog IS a branching program over a group (the SU(2) subgroup generated by the braid generators). The writhe character maps the braid word to Z/8Z ⊂ abelian, which by Barrington cannot compute any non-trivial function of the input bits' parity.</p>
<p>This grounding means: <ul> <li>DKC's computational structure is not an artifact of the specific numerics but reflects genuine complexity-theoretic constraints that hold for ALL group-theoretic branching programs.</li> <li>The solvability bottleneck (<a href="../inventory/entries/demo_94.html">D94</a>: 2I beats z8 at matched size) is Barrington's theorem made quantitative in the DKC setting.</li> <li>The radical is NOT merely experimentally weak — it is theoretically blocked. This upgrades the <a href="../inventory/entries/demo_100.html">D100</a>-<a href="../inventory/entries/demo_101.html">D101</a> observation from "non-semisimple modules empirically outperform simple ones" to the sharper claim: "the extension structure is load-bearing, but the radical direction itself is provably inert."</li> <li>For the hybrid LLM: compiled DKC neurons using non-semisimple modules should leverage the quotient structure (mixing row, Ext^1 coupling), not the radical direction. Catalog engineering can safely ignore radical content when optimizing for parity/XOR.</li> </ul>
<p>Status: THEOREM (named, computationally verified at all 32,768 entries of the 6-strand catalog). Barrington's theorem is classical; the connection to TL radical structure is ours.</p>
<h3>19. The Amy Bridge: DKC Meets Quantum Circuit Synthesis — NEW (<a href="../inventory/entries/demo_108.html">D108</a>)</h3>
<p><a href="../inventory/entries/demo_108.html">D108</a>'s Dual-Channel Theorem produces a second external bridge — this time to quantum circuit synthesis. The mapping:</p>
<p><code></code>` DKC Dual Channel                  Quantum Circuit Synthesis ──────────────────                ───────────────────────── Multiplicative phase coherence    T-gate (phase rotation by pi/4)   (product closure)                 — phase resource Additive magnitude diversity      Hadamard (reflection, magnitude mixing)   (v_2 connectivity)                — entanglement resource Parity needs BOTH channels        Universal gate set needs BOTH T + H Poison fails BOTH channels        Non-universal gate sets are incomplete <code></code>`</p>
<p>Amy, Glaudell &amp; Ross (2023) established the exact synthesis framework for single-qubit unitaries over Z[1/sqrt(2), zeta_8] — the same ring as DKC's weight algebra. Their sde (smallest denominator exponent) resource measure counts the minimal T-gate depth needed to synthesize a given unitary. The DKC catalog's product closure structure may be the combinatorial counterpart of the sde hierarchy.</p>
<p><strong>Why this matters for the vision:</strong></p>
<ul>
<li>DKC and quantum circuit synthesis share the same algebraic substrate: Z[zeta_8], the binary octahedral group, and the interplay between phase rotation and magnitude mixing.</li>
<li>The Amy bridge opens a new audience: the quantum compilation community already has tools, theorems, and intuitions about this exact ring. DKC's contribution would be the topological origin story (why this ring and this group from braids/knots).</li>
<li>The sde resource measure from quantum synthesis may be directly applicable to DKC catalog optimization: entries with low sde might correspond to computationally cheap weights.</li>
<li>More speculatively: if DKC weights can be interpreted as quantum circuit elements, then compiling a DKC neuron IS compiling a quantum circuit. This would mean the hybrid LLM's compiled portion is, in some precise sense, a quantum computation executed on classical hardware via the algebraic bridge.</li>
</ul>
<p>Status: CONJECTURED (<a href="../inventory/entries/demo_108.html">D108</a>). The structural mapping is clear; the formal equivalence between DKC product closure and sde resource hierarchy is unproven. A dedicated investigation would need to compute sde for DKC catalog entries and correlate with parity capability.</p>
<h3>20. Sign-Hash as 1-Bit Compressed Sensing — NEW (<a href="../inventory/entries/demo_103.html">D103</a>-<a href="../inventory/entries/demo_105.html">D105</a>)</h3>
<p>The sign-hash activation used in multi-strand DKC maps each matrix entry to {-1, 0, +1} — a ternary quantization. <a href="../inventory/entries/demo_104.html">D104</a> discovered that this quantization can INCREASE effective rank: raw rank 244 of 324 (W_{6,2}) becomes sign-rank 292 — a gain of 48 independent directions. The nonlinear sign() function breaks linear dependencies over the integers.</p>
<p>This connects directly to the 1-bit compressed sensing literature (Boufounos-Baraniuk 2008, Plan-Vershynin 2014): sign measurements of high-dimensional vectors preserve metric structure up to a scaling factor. The DKC instantiation is novel because: <ul> <li>The vectors are braid representation matrices over cyclotomic integers (not generic Gaussian vectors).</li> <li>The sign quantization interacts with the algebraic structure (axis- alignment at delta=0 means sign patterns have a predictable Z/4Z structure from <a href="../inventory/entries/demo_107.html">D107</a>).</li> <li>The Atkinson sweet spot (<a href="../inventory/entries/demo_104.html">D104</a>: non-monotonic component-count curve peaking at ~120 of 324 components) suggests an optimal information-per- collision tradeoff analogous to optimal measurement design in compressed sensing.</li> </ul>
<p><strong>Implication for the vision:</strong></p>
<p>For multi-strand compiled DKC neurons, the readout mechanism (sign-hash) is not just a discretization — it is a structured compression that can preserve or even enhance the algebraic information content. The Atkinson sweet spot provides a concrete design criterion: hash FEWER components than the matrix dimension, choosing which components to include based on the branching decomposition (<a href="../inventory/entries/demo_104.html">D104</a>: off-diagonal cross-block components carry the signal at small block dimension; within-block at large).</p>
<p>The sign-rank expansion phenomenon (W_{8,2}: 1.83x expansion and still growing at 16K entries) also means that multi-strand DKC neurons may be more powerful than their raw linear-algebraic rank suggests — the nonlinear activation creates independence that the linear algebra does not have.</p>
<p>Status: DEMONSTRATED (<a href="../inventory/entries/demo_104.html">D104</a>-<a href="../inventory/entries/demo_105.html">D105</a>). The compressed sensing connection is structural; a formal reduction to 1-bit CS theory is open.</p>
<h3>21. Raqiya as Predictive Diagnostic — NEW (<a href="../inventory/entries/demo_107.html">D107</a>-<a href="../inventory/entries/demo_109.html">D109</a>)</h3>
<p>Raqiya — the single-header C89 library for Z[zeta_8] algebraic analysis — evolved across <a href="../inventory/entries/demo_107.html">D107</a>-<a href="../inventory/entries/demo_109.html">D109</a> from a measurement tool to a predictive diagnostic. The progression:</p>
<p><strong><a href="../inventory/entries/demo_107.html">D107</a></strong>: Raqiya measures the algebraic graph structure of a value set (axis alignment, product closure, additive closure, quotient graphs). The Z/4Z axis-alignment theorem gives these measurements a theoretical grounding: every braid matrix entry is axis-aligned at delta=0, so Raqiya's detectors are measuring inherent algebraic structure, not numerical artifacts.</p>
<p><strong><a href="../inventory/entries/demo_108.html">D108</a></strong>: Raqiya's graph analysis PREDICTS parity capability. Product closure &gt; 0 is necessary for parity; partition coincidence (root = Galois = norm) is a structural signature of incapacity. Six pre-registered predictions, four confirmed. The Dual-Channel Theorem establishes that the two Raqiya channels (multiplicative product closure + additive v_2 connectivity) jointly discriminate parity from poison vocabularies.</p>
<p><strong><a href="../inventory/entries/demo_109.html">D109</a></strong>: Raqiya's prediction is encoding-dependent. At delta=0 (additive encoding), parity wants HIGH product closure. At delta=sqrt(2) (multiplicative encoding), parity wants LOW product closure — the polarity inverts. More importantly, at delta=sqrt(2) the algebra is so rich (j=0 sector alive) that Raqiya CANNOT discriminate: 7 of 8 edge types are identical between parity and non-parity. Raqiya diagnoses algebraic IMPOVERISHMENT, not algebraic health.</p>
<p><strong>Why this matters for the vision:</strong></p>
<p>Raqiya is the first tool in the DKC pipeline that enables "predict then verify" instead of "search and hope." For the hybrid LLM compilation pipeline:</p>
<ul>
<li><strong>Pre-screening</strong>: before running an expensive exhaustive XOR search on a candidate catalog, run Raqiya's graph analysis. If product closure = 0 and partition hierarchy is flat, the catalog is structurally incapable — no need to search.</li>
<li><strong>Encoding selection</strong>: Raqiya's encoding-dependent polarity (<a href="../inventory/entries/demo_108.html">D108</a> vs <a href="../inventory/entries/demo_109.html">D109</a>) provides a concrete diagnostic: check product closure polarity to determine whether the additive or multiplicative encoding is appropriate for a given value vocabulary.</li>
<li><strong>Scalability</strong>: Raqiya analysis is O(n^2) in catalog size (pairwise products and sums), while exhaustive XOR search is O(n^k) in weight count. Pre-screening with Raqiya is exponentially cheaper.</li>
<li><strong>Reusable infrastructure</strong>: the library is exact (integer arithmetic), tested (208+ unit tests), and C89-compliant — it embodies the rhubarb philosophy of tools that last.</li>
</ul>
<p>Status: OPERATIONAL (deployed across <a href="../inventory/entries/demo_107.html">D107</a>-<a href="../inventory/entries/demo_109.html">D109</a>, 208+ tests). Predictive power demonstrated for parity discrimination at delta=0 (<a href="../inventory/entries/demo_108.html">D108</a>). The delta- dependent diagnostic (<a href="../inventory/entries/demo_109.html">D109</a>) extends the tool's range. Deployment to ζ₁₂ catalogs (where the algebra is infinite and structurally richer) is the next validation target.</p>
<h3>22. The Bypass Principle as Fundamental Architecture — NEW (<a href="../inventory/entries/demo_102.html">D102</a>-<a href="../inventory/entries/demo_109.html">D109</a> Synthesis)</h3>
<p>Across 109 demos, 30 distinct obstructions have been identified and classified into 9 families. Of these 30, exactly 26 have known bypass routes — an 87% bypass rate. The 13% without known bypasses are in secondary research questions (b-parameter valuation, dynamical entropy null), not in the core DKC Boolean computation pipeline. The core pipeline has a 100% bypass rate across 22 obstructions.</p>
<p><strong>The structural principle:</strong></p>
<p>The algebra is always richer than the readout. Every wall in the DKC pipeline has been in the INTERFACE between the algebra and the observer — the activation, the encoding, the readout mechanism, the k-regime — never in the algebra itself. The bracket lattice at ζ₈ contains Aizenberg's parity construction; it ALWAYS had what computation needed. The progression of discoveries was always about learning to READ what was already there.</p>
<p><code></code>` Wall                              Component         Type           Bypass ───────────────────────────       ─────────         ────           ────── Parity under half-plane (<a href="../inventory/entries/demo_48.html">D48</a>)     Activation        Parametric     k=6 (<a href="../inventory/entries/demo_50.html">D50</a>) XOR6 at standard sectors (<a href="../inventory/entries/demo_63.html">D63</a>)    Convention        Parametric     k=24 gen (<a href="../inventory/entries/demo_65.html">D65</a>) XOR8 at S² only (<a href="../inventory/entries/demo_76.html">D76</a>)             Activation        Parametric     S¹×S² (<a href="../inventory/entries/demo_77.html">D77</a>) XOR10 at ζ₈ (<a href="../inventory/entries/demo_78.html">D78</a>)                 Root of unity     Structural     ζ₁₂ (<a href="../inventory/entries/demo_79.html">D79</a>) Parity-lock under ±q (<a href="../inventory/entries/demo_92.html">D92</a>)        Encoding          Structural     1wpi (<a href="../inventory/entries/demo_48.html">D48</a>) Complement-blindness (<a href="../inventory/entries/demo_93.html">D93</a>)        Activation        Fragile        phase_cell (<a href="../inventory/entries/demo_93.html">D93</a>) Trace collapse 3-strand (<a href="../inventory/entries/demo_98.html">D98</a>)     Readout           Structural     Δ₁ module (<a href="../inventory/entries/demo_99.html">D99</a>) Curse of dim in sign-hash (<a href="../inventory/entries/demo_103.html">D103</a>)  Activation        Parametric     Atkinson (<a href="../inventory/entries/demo_104.html">D104</a>) XOR dies at N≥7 (<a href="../inventory/entries/demo_93.html">D93</a>)             k-regime          Parametric     k=4096 (<a href="../inventory/entries/demo_105.html">D105</a>) <code></code>`</p>
<p><strong>Why this matters for the vision:</strong></p>
<p>The bypass principle is the strongest meta-result of the program. It means:</p>
<p>1. <strong>When a wall appears, diagnose the component.</strong> The DKC pipeline has    enough independently variable components (root, encoding, activation,    readout, module, k) that most obstructions can be circumvented by    changing ONE component while holding everything else fixed. This is    a design-space property, not luck.</p>
<p>2. <strong>The compilation pipeline should be modular.</strong> Each component (encoding,    activation, catalog depth, root of unity, module choice, readout    function) is a separately configurable stage. Walls are localized to    stages. This directly informs the hybrid LLM architecture: the compiled    portion should expose these as independent knobs.</p>
<p>3. <strong>The architecture is fundamentally robust.</strong> A system where every wall    has a bypass is a system that can adapt. For the long-term vision of    compiled knowledge that lasts, this robustness means the approach is not    fragile to any single design choice — there are always alternative    configurations.</p>
<p>4. <strong>The diagnostic sequence is now concrete:</strong>    (a) Which pipeline component enforces the wall?    (b) Is it parametric (tunable) or structural (architectural change)?    (c) Does changing that one component resolve it?    (d) If not, which deeper layer is actually responsible?    This four-step sequence has resolved every obstruction in 109 demos.</p>
<p>Status: SYNTHESIS (from obstructions.md). The bypass rate is an empirical observation across 109 demos. Whether it continues at 87%+ for future obstructions is an open question — but the structural argument (the algebra is richer than the readout) suggests it will.</p>
<h3>23. The Discrete Algebraic Reservoir Computer — MATURE FRAMING (<a href="../inventory/entries/demo_94.html">D94</a>→<a href="../inventory/entries/demo_102.html">D102</a>-<a href="../inventory/entries/demo_109.html">D109</a>)</h3>
<p>The "discrete algebraic reservoir computer" framing proposed in <a href="../inventory/entries/demo_94.html">D94</a> has matured through <a href="../inventory/entries/demo_102.html">D102</a>-<a href="../inventory/entries/demo_109.html">D109</a> from a structural analogy to a concrete characterization with tested predictions.</p>
<p><strong>The maturation path:</strong></p>
<p><a href="../inventory/entries/demo_94.html">D94</a> proposed the mapping: fixed catalog = reservoir, Cayley graph = connectivity, signed sum = linear readout, activation = nonlinear output, BFS depth = memory depth. This was a structural observation.</p>
<p><a href="../inventory/entries/demo_102.html">D102</a>-<a href="../inventory/entries/demo_105.html">D105</a> TESTED the reservoir framing against multi-strand DKC: <ul> <li>BFS growth is a braid group invariant (<a href="../inventory/entries/demo_102.html">D102</a>-<a href="../inventory/entries/demo_103.html">D103</a>): the reservoir topology depends only on the braid group B_n, not the module — exactly as a reservoir's connectivity should be input-independent.</li> <li>Module choice affects readout, not the reservoir (<a href="../inventory/entries/demo_102.html">D102</a>-<a href="../inventory/entries/demo_103.html">D103</a>): different modules of B_6 produce identical BFS catalogs but different XOR capacities through different readout components. The reservoir is fixed; the readout varies.</li> <li>k is the real lever (<a href="../inventory/entries/demo_104.html">D104</a>-<a href="../inventory/entries/demo_105.html">D105</a>): activation resolution (k) determines capacity, not hash architecture. The reservoir's output is determined by how finely you read it, not how complexly you combine readings.</li> <li>Rank saturation (<a href="../inventory/entries/demo_105.html">D105</a>): the reservoir has a well-defined effective dimension that can be measured through sign-rank at saturation. This is the reservoir's computational capacity in the RC sense.</li> </ul>
<p><a href="../inventory/entries/demo_106.html">D106</a>-<a href="../inventory/entries/demo_109.html">D109</a> added the DIAGNOSTIC layer: <ul> <li>The TL visibility filter (<a href="../inventory/entries/demo_106.html">D106</a>) tells you which reservoir properties matter (writhe-like, algebraic) and which don't (dynamical, entropic).</li> <li>Raqiya (<a href="../inventory/entries/demo_107.html">D107</a>-<a href="../inventory/entries/demo_109.html">D109</a>) is the reservoir's diagnostic tool: graph analysis predicts computational capability without running the full computation.</li> <li>The encoding-dependent dual-channel (<a href="../inventory/entries/demo_108.html">D108</a>-<a href="../inventory/entries/demo_109.html">D109</a>) shows the reservoir has different computational profiles under different input couplings — exactly the reservoir computing prediction that input-reservoir coupling determines what the reservoir can compute.</li> </ul>
<p><strong>The precise mapping (updated from <a href="../inventory/entries/demo_94.html">D94</a>):</strong></p>
<table><thead><tr><th>Reservoir Computing</th><th>DKC Analog</th><th>Status</th></tr></thead><tbody><tr><td>Fixed reservoir</td><td>Quaternion catalog (BFS closure)</td><td>PROVEN invariant (<a href="../inventory/entries/demo_102.html">D102</a>)</td></tr><tr><td>Input coupling</td><td>Encoding (±q or 1wpi)</td><td>PROVEN to determine function repertoire (<a href="../inventory/entries/demo_92.html">D92</a>)</td></tr><tr><td>Reservoir topology</td><td>Cayley graph of B_n image</td><td>PROVEN braid-group-only (<a href="../inventory/entries/demo_102.html">D102</a>-<a href="../inventory/entries/demo_103.html">D103</a>)</td></tr><tr><td>Linear readout</td><td>Signed quaternion sum</td><td>STANDARD since <a href="../inventory/entries/demo_29.html">D29</a></td></tr><tr><td>Nonlinear output</td><td>Activation (phase_cell/sign-hash/Voronoi)</td><td>CHARACTERIZED (<a href="../inventory/entries/demo_103.html">D103</a>-<a href="../inventory/entries/demo_105.html">D105</a>)</td></tr><tr><td>Memory depth</td><td>BFS crossing depth</td><td>PROVEN linear capacity law (<a href="../inventory/entries/demo_82.html">D82</a>)</td></tr><tr><td>Separation property</td><td>XOR capacity</td><td>PREDICTED by Raqiya (<a href="../inventory/entries/demo_108.html">D108</a>)</td></tr><tr><td>Echo state property</td><td>BFS closure convergence</td><td>OBSERVED at all finite groups</td></tr><tr><td>Reservoir diagnostic</td><td>Raqiya graph analysis</td><td>OPERATIONAL (<a href="../inventory/entries/demo_107.html">D107</a>-<a href="../inventory/entries/demo_109.html">D109</a>)</td></tr></tbody></table>
<p>The framing is now testable, predictive, and tool-supported. The RKHS kernel rank test from <a href="../inventory/entries/demo_94.html">D94</a> remains the quantitative validation target: rank(K_2I)/rank(K_z8) &gt; 120/24 if non-solvability contributes above raw catalog size.</p>
<p><strong>Connection to the vision:</strong></p>
<p>The discrete algebraic reservoir computer is what a compiled DKC neuron IS — not metaphorically but precisely. For the hybrid LLM: <ul> <li>The reservoir (catalog) is compiled from topology.</li> <li>The input coupling (encoding) is compiled from the Boolean function specification.</li> <li>The readout (activation) is an engineering design parameter.</li> <li>The capacity is predictable from depth (<a href="../inventory/entries/demo_82.html">D82</a>), diagnosable from algebraic graph structure (<a href="../inventory/entries/demo_108.html">D108</a>), and guaranteed by the bypass principle (Section 22).</li> </ul>
<p>This means the compilation pipeline is: (1) choose root/strand count for the reservoir, (2) build BFS to required depth for the target function arity, (3) diagnose the catalog with Raqiya to verify capability, (4) select encoding based on the target Boolean function, (5) tune activation resolution k until sufficient capacity is achieved.</p>
<p>Status: MATURE FRAMING. Structural mapping complete. Predictive diagnostics operational. RKHS kernel test pending. The framing has been tested against <a href="../inventory/entries/demo_102.html">D102</a>-<a href="../inventory/entries/demo_109.html">D109</a> arc results without contradiction.</p>
<p>---</p>
<h2>Connection to Broader Rhubarb Project</h2>
<p>The hybrid LLM vision connects to rhubarb's larger goals: <ul> <li><strong>Long-term thinking</strong>: A model whose factual knowledge can be precisely curated and corrected is a model that can serve for decades, not months.</li> <li><strong>No dependencies</strong>: Compiled weights from algebraic structure, not from training infrastructure that rots.</li> <li><strong>Latin / Catholic intellectual tradition</strong>: Scholastic logic IS taxonomy + syllogism. The Summa is structured as syllogistic arguments. This is computation native to the tradition.</li> <li><strong>Smaragda</strong>: Already a taxonomy/entity system. Natural source of structured knowledge for the compilation pipeline.</li> </ul>
<p><strong>The depth law as a cost model for compilation (updated, <a href="../inventory/entries/demo_82.html">D82</a>):</strong></p>
<p>The linear depth law (max_xor ≈ depth + 6) gives DKC compilation a concrete cost structure for the first time. Specifically: <ul> <li>A compiled neuron capable of expressing an n-input Boolean function requires catalog entries of crossing depth ≈ n - 6. For a 3-input syllogism (XOR3), depth 0 entries suffice. For a 6-input composition, depth ≈ 0 entries still suffice (XOR6 at depth 0). For higher-arity compiled functions, depth scales linearly with arity.</li> <li>More complex knots = more powerful compiled neurons. This is a direct translation: the crossing complexity of a braid used to generate a catalog entry determines the computational power that entry contributes.</li> <li>Catalog construction cost scales exponentially with depth (<a href="../inventory/entries/demo_82.html">D82</a>: ~2× per round). But the gain is linear. This means: for the hybrid LLM, there is a sweet spot where you build the catalog to the depth you need and stop. You don't need the entire infinite group — just the first d rounds for XOR(d+6).</li> <li>The two-component winner structure (shallow core + deep extensions) maps onto the hybrid LLM's architecture: the "shallow core" of a compiled neuron (generators and depth-0 entries) plays the role of the fixed logical skeleton, while the "deep extensions" provide the fine-grained capacity for more complex computations. This parallels the compiled (skeletal, exact) vs. trained (fine-grained, statistical) distinction in the hybrid model itself.</li> </ul>
<p>For building a practical hybrid LLM, this means: catalog depth is a hyperparameter that you set based on the maximum arity of logical functions you want to compile. For syllogistic logic (arity 3), the catalog is trivially small. For richer logical operations (arity 8-12), you need ~5-8 rounds of BFS at ζ₁₂. This is a concrete engineering specification, not just a theoretical result.</p>
<p>---</p>
<h2>Open Architectural Questions</h2>
<ul>
<li>What's the right granularity? Is each fact one DKC neuron, a cluster, or something else?</li>
<li>How does the compiled portion influence the statistical portion during inference? (Hard facts constraining soft associations?)</li>
<li>Can compiled weights serve as "guardrails" preventing hallucination in specific domains?</li>
<li>Is there a natural attention mechanism that routes factual queries to compiled weights and associative queries to trained weights?</li>
<li>How does the opaque token substitution mechanism work in practice? Is it a simple lookup table, or does it need to handle morphological variation (e.g., "bear" → "bears" → "bear's")?</li>
<li>What happens when two compiled syllogisms share a term? Do their weight regions need to be connected? How does the net compose syllogistic chains?</li>
<li>Does the acceleration thesis (compiled scaffolding → faster statistical training) have any theoretical grounding, or is it purely a hypothesis to test empirically?</li>
<li>Can the "graceful ignorance" mechanism (recognizing when you lack a compiled subnet) be made reliable? What does the net's output look like when it doesn't know something?</li>
<li>How does the deterministic parser handle ambiguity? "All bank employees are mammals" requires disambiguation (bank=financial vs bank=riverbank) before syllogistic compilation.</li>
</ul>
<ul>
<li><strong>Quantum information connection</strong>: DKC computation lives on S²=CP¹ (the Bloch sphere). The 13-direction eigenvector Voronoi might correspond to a known quantum measurement basis. The l=6 spherical harmonic bandwidth maps to hexadecapole operators in quantum optics. Is there a formal connection between DKC compiled weights and quantum circuits, beyond the geometric analogy?</li>
<li><strong>Matroid structure of the catalog</strong>: The 44 good / 31 poison value split in the DKC catalog may reflect a matroid structure (Reiner's cyclotomic matroids mu_8). If so, matroid membership tests would provide poly-time extensibility checking — replacing exhaustive catalog search.</li>
</ul>
<p>---</p>
<p><em>First recorded: 2026-02-20. Source: conversation during atlas defrag.</em> *Updated: 2026-02-20. Source: second vision discussion — opaque tokens, syllogism-as-training, wired integration, deterministic NL parser.* <em>Updated: 2026-02-20. <a href="../inventory/entries/demo_63.html">D63</a> resolved Gap 6 scaling (parity ceiling n=5).</em> *Updated: 2026-02-21. <a href="../inventory/entries/demo_64.html">D64</a>-<a href="../inventory/entries/demo_71.html">D71</a> quaternionic arc: Gap 6 fully resolved, Gap 7 (two-layer wall) and Gap 8 (quaternionic DKC / Bloch sphere) added. New research axes: quaternionic DKC, spectral theory, music, matroid theory, activation function design theory.* *Updated: 2026-02-21. <a href="../inventory/entries/demo_72.html">D72</a>-<a href="../inventory/entries/demo_82.html">D82</a> scaling arc: finite/infinite group boundary, depth law, activation determines capacity. Gap 6 further revised (ζ₈ ceiling at XOR8 with S¹×S² activation; ζ₁₂ breaks the wall; depth is the fundamental variable, not catalog size). Gap 9 added (finite vs infinite group choice; ADE classification; quantum dimension vanishing). Research axes 6 and 7 added (depth-based catalog engineering; finite/infinite group duality). Near-term explorations 7-9 added (ζ₁₂ activation zoo; ζ₃₂ finiteness; direct deep-entry generation). Connection to Broader Rhubarb Project updated with depth law as compilation cost model.* *Updated: 2026-02-21. <a href="../inventory/entries/demo_83.html">D83</a>-<a href="../inventory/entries/demo_84.html">D84</a> arc: resource decomposition (lattice + depth + writhe, each +2 XOR independently), framing as computational content inverting 35-year TQFT assumption (Witten 1989), null states as RC separation-property maintainers, LCFT bridge (Jordan cells, dense polymer c=-2, Gurarie b-number), non-semisimplicity as THE resource (<a href="../inventory/entries/demo_50.html">D50</a>→<a href="../inventory/entries/demo_82.html">D82</a>→<a href="../inventory/entries/demo_84.html">D84</a> convergence). Research axes 8-11 added. Near-term explorations 10-11 added (indecomposability parameter b calculation, dense polymer fusion rules). Three-way LCFT↔TQC↔RC intersection identified as novel.* *Updated: 2026-02-24. <a href="../inventory/entries/demo_85.html">D85</a>-<a href="../inventory/entries/demo_92.html">D92</a> mechanistic arc: Gap 10 added (encoding design — <a href="../inventory/entries/demo_92.html">D92</a> parity-lock theorem proves encoding determines computability, more fundamental than activation or catalog). Research axes 12-15 added: encoding as design dimension (<a href="../inventory/entries/demo_92.html">D92</a>), relational computation thesis (<a href="../inventory/entries/demo_89.html">D89</a>-<a href="../inventory/entries/demo_91.html">D91</a>, spectral inversion proves positional optimization is wrong), regime-dependent design (<a href="../inventory/entries/demo_87.html">D87</a>-<a href="../inventory/entries/demo_88.html">D88</a>, finite vs infinite group principles differ qualitatively), formal proofs as maturing framework (P04 parity-lock, pipeline of P05-P07). Near-term explorations 10-11 marked DONE/partial, 12-16 added (1wpi depth law, encoding space exploration, balanced exponentials proof, regime transition threshold, relational activation function).* *Updated: 2026-02-24. <a href="../inventory/entries/demo_93.html">D93</a>-<a href="../inventory/entries/demo_94.html">D94</a> circuit complexity and group structure arc: Research axis 16 added (DKC as Discrete Algebraic Reservoir Computer — FIVE- PILLAR SYNTHESIS COMPLETE). <a href="../inventory/entries/demo_93.html">D93</a>: complement-blindness theorem, phase_cell recovery of all 13 NPN classes, circuit complexity hierarchy (AND/XOR ratio 1.01→infinity, N=3-8), pigeonhole mechanism identified. <a href="../inventory/entries/demo_94.html">D94</a>: binary icosahedral group 2I (E₈) reached via Z[sqrt5] exact arithmetic, solvability bottleneck confirmed (Barrington), circuit complexity hierarchy universal across groups, crossover hypothesis demonstrated (2I overtakes z12 at N=6-7), "discrete algebraic reservoir computer" framing proposed with testable kernel-rank prediction. Gap 9 updated (E₈/2I resolved). Near-term explorations 17-21 added (<a href="../inventory/entries/demo_95.html">D95</a> RKHS kernel rank, higher k_sec with 2I, depth law under phase_cell, Fibonacci parameter direct test, cross-depth 2I analysis). Paper 8 path identified: circuit complexity + five-pillar synthesis.* *Updated: 2026-02-24. <a href="../inventory/entries/demo_95.html">D95</a>-<a href="../inventory/entries/demo_101.html">D101</a> multi-strand DKC arc: Research axis 17 added (Multi-Strand DKC and the sl_d Functor Thesis). <a href="../inventory/entries/demo_95.html">D95</a>: commutator depth and cross-layer synergy (COMM+NON-COMM 2.7x boost, cross-layer synergy 0+0=26%). <a href="../inventory/entries/demo_96.html">D96</a>: LANDMARK — TL-group cross-classification, 5-cell landscape, Cell B 100% XOR perfection, optimal z8 catalog = A+B+C (21 entries). <a href="../inventory/entries/demo_97.html">D97</a>: Cell B geometric inevitability, orthogonal-frame proof, 50-degree robust plateau. <a href="../inventory/entries/demo_98.html">D98</a>: 3-strand proof of concept, infinite group (2048 entries), readout bottleneck (trace=0, column=100%). <a href="../inventory/entries/demo_99.html">D99</a>: LANDMARK — first-ever 3-strand XOR (XOR6=500K, XOR14=60), Ext^1 catalytic preparation thesis, two-regime hypothesis. <a href="../inventory/entries/demo_100.html">D100</a>: 4-strand W_{4,2}, 3x3 matrices, ~3.1x growth, Casimir-XOR correlation. <a href="../inventory/entries/demo_101.html">D101</a>: 5-strand W_{5,3}, sl_d functor confirmed (~4x growth), hub count falsified (3 not 12), Casimir inversion in simple modules, XOR14=0 ceiling. Near-term explorations 17 marked repurposed, 22-27 added (W_{6,4} decisive test, radical content study, multi-strand activation zoo, Fibonacci parameter, artificial perfect cell, non-semisimple TQFT formalization). Key findings: Ext^1 extensions are computationally load-bearing; simple vs non-semisimple modules produce qualitatively different computation; readout design is the multi-strand frontier; sl_d functor provides systematic program for all strand counts.* *Updated: 2026-02-26. <a href="../inventory/entries/demo_102.html">D102</a>-<a href="../inventory/entries/demo_109.html">D109</a> multi-strand maturation and algebraic diagnostics arc: Research axes 18-23 added (Barrington bridge to circuit complexity, Amy bridge to quantum circuit synthesis, sign-hash as 1-bit compressed sensing, Raqiya as predictive diagnostic, the bypass principle as fundamental architecture, discrete algebraic reservoir computer framing matured). Near-term explorations 22 marked DONE (W_{6,4}), 28-33 added (encoding-dependent catalog optimization, Raqiya at zeta_12, j=0 liveness conjecture, Amy bridge formalization, TL visibility filter formal proof, dual-channel theorem at higher strand counts). Key findings: radical carries abelian character provably useless for parity (Barrington-Radical Principle); BFS growth is braid group invariant (proven at n=6, 3 modules); sign-hash curse of dimensionality + Atkinson sweet spot; macrame principle regime transition; topological entropy totally orthogonal to computation; Z/4Z axis- alignment theorem with constructive phase formula; dual-channel theorem predicts parity capability from graph structure; encoding determines dual- channel polarity; Raqiya diagnoses algebraic impoverishment not health; 87% bypass rate across all obstructions.*</p>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/c.min.js"></script>
    <script>hljs.highlightAll();</script>
</body>
</html>